[toc]



# Redis 持久化

## 1.持久化简介

**Redis** 的数据 **全部存储** 在 **内存** 中，如果 **突然宕机**，数据就会全部丢失，因此必须有一套机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的 **持久化机制**，它会将内存中的数据库状态 **保存到磁盘** 中。



### 1.1.持久化发生了什么 | 从内存到磁盘

我们来稍微考虑一下 **Redis** 作为一个 **"内存数据库"** 要做的关于持久化的事情。通常来说，从客户端发起请求开始，到服务器真实地写入磁盘，需要发生如下几件事情：

![image-20210228224505429](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228224505429.png)

**详细版** 的文字描述大概就是下面这样：

1. 客户端向数据库 **发送写命令** *(数据在客户端的内存中)*
2. 数据库 **接收** 到客户端的 **写请求** *(数据在服务器的内存中)*
3. 数据库 **调用系统 API** 将数据写入磁盘 *(数据在内核缓冲区中)*
4. 操作系统将 **写缓冲区** 传输到 **磁盘控控制器** *(数据在磁盘缓存中)*
5. 操作系统的磁盘控制器将数据 **写入实际的物理媒介** 中 *(数据在磁盘中)*

**注意:** 上面的过程其实是 **极度精简** 的，在实际的操作系统中，**缓存** 和 **缓冲区** 会比这 **多得多**...



### 1.2.如何尽可能保证持久化的安全

如果我们故障仅仅涉及到 **软件层面** *(该进程被管理员终止或程序崩溃)* 并且没有接触到内核，那么在 *上述步骤 3* 成功返回之后，我们就认为成功了。即使进程崩溃，操作系统仍然会帮助我们把数据正确地写入磁盘。

如果我们考虑 **停电/ 火灾** 等 **更具灾难性** 的事情，那么只有在完成了第 **5** 步之后，才是安全的。

所以我们可以总结得出数据安全最重要的阶段是：**步骤三、四、五**，即：

- 数据库软件调用写操作将用户空间的缓冲区转移到内核缓冲区的频率是多少？
- 内核多久从缓冲区取数据刷新到磁盘控制器？
- 磁盘控制器多久把数据写入物理媒介一次？
- **注意：** 如果真的发生灾难性的事件，我们可以从上图的过程中看到，任何一步都可能被意外打断丢失，所以只能 **尽可能地保证** 数据的安全，这对于所有数据库来说都是一样的。

我们从 **第三步** 开始。Linux 系统提供了清晰、易用的用于操作文件的 `POSIX file API`，`20`多年过去，仍然还有很多人对于这一套 `API` 的设计津津乐道，我想其中一个原因就是因为你光从 `API` 的命名就能够很清晰地知道这一套 API 的用途：

```c
int open(const char *path, int oflag, .../*,mode_t mode */);
int close (int filedes);int remove( const char *fname );
ssize_t write(int fildes, const void *buf, size_t nbyte);
ssize_t read(int fildes, void *buf, size_t nbyte);
```

- 参考自：API 设计最佳实践的思考 - https://www.cnblogs.com/yuanjiangw/p/10846560.html

所以，我们有很好的可用的 `API` 来完成 **第三步**，但是对于成功返回之前，我们对系统调用花费的时间没有太多的控制权。

然后我们来说说 **第四步**。我们知道，除了早期对电脑特别了解那帮人 *(操作系统就这帮人搞的)*，实际的物理硬件都不是我们能够 **直接操作** 的，都是通过 **操作系统调用** 来达到目的的。为了防止过慢的 I/O 操作拖慢整个系统的运行，操作系统层面做了很多的努力，譬如说 **上述第四步** 提到的 **写缓冲区**，并不是所有的写操作都会被立即写入磁盘，而是要先经过一个缓冲区，默认情况下，Linux 将在 **30 秒** 后实际提交写入。

但是很明显，**30 秒** 并不是 Redis 能够承受的，这意味着，如果发生故障，那么最近 30 秒内写入的所有数据都可能会丢失。幸好 `PROSIX API` 提供了另一个解决方案：`fsync`，该命令会 **强制** 内核将 **缓冲区** 写入 **磁盘**，但这是一个非常消耗性能的操作，每次调用都会 **阻塞等待**直到设备报告 IO 完成，所以一般在生产环境的服务器中，**Redis** 通常是每隔 1s 左右执行一次 `fsync` 操作。

到目前为止，我们了解到了如何控制 `第三步` 和 `第四步`，但是对于 **第五步**，我们 **完全无法控制**。也许一些内核实现将试图告诉驱动实际提交物理介质上的数据，或者控制器可能会为了提高速度而重新排序写操作，不会尽快将数据真正写到磁盘上，而是会等待几个多毫秒。这完全是我们无法控制的。



## 2.Redis 中的两种持久化方式

### 2.1.方式一：AOF 日志

`AOF`(`Append Only File`)日志称之为**「写后日志」**，即是命令先执行完成，把数据写入内存，然后才会记录日志。

`AOF`日志（文本形式）会将收到每一条的命令且执行成功的命令以一定的格式写入到文本中（追加的方式）。

**「写后日志有什么好处呢？」** 如下：

1. 对于写前日志无论命令是否执行成功都会被记录，但是`Redis`的写后日志则只有命令执行成功才会被写入日志，避免了日志中存在错误命令；
2. 同时由于是命令执行成功之后才会写入日志，因此不会阻塞当前命令的执行。

但是`AOF`日志也有**「潜在的风险」**，分析如下：

1. 由于是写后日志，如果在命令执行成功之后，在日志未写入磁盘之前服务器突然宕机，那重启恢复数据的时候，这部分的数据肯定在日志文件中不存在了，那么将会丢失。（无法通过后台数据库恢复的情况下）
2. 虽然不会阻塞当前命令的执行，由于记录日志也是在主线程中（`Redis`是单线程），如果日志写入磁盘的时候突然阻塞了，肯定会影响下一个命令的执行。

为了解决上面的风险，`AOF`日志提供了三种回写策略。

#### 2.1.1.三种写回策略

`AOF`机制提供了三种回写策略，这些都在`appendfsync`配置，如下：

1. `Always`（同步写回）：命令执行完成，立马同步的将日志写入磁盘
2. `Everysec`（每秒写回）：命令执行完成后，先将日志写入 AOF 文件的内存缓冲区，每隔一秒把缓冲区中内容写入磁盘。
3. `No`(操作系统控制的写回)：每个写命令执行完，只是先把日志写到`AOF`文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。

其实这三中写回策略都无法解决主线程的阻塞和数据丢失的问题，分析如下：

1. `同步写回`：基本不丢失数据，但是每步操作都会有一个慢速的落盘操作，不可避免的影响主线程性能。
2. `每秒写回`：采用一秒写一次到 AOF 日志文件中，但是一旦宕机还是会丢失一秒的数据。
3. `操作系统控制的写回`：在写完缓冲区之后则会写入磁盘，但是数据始终在缓冲区的时间内一旦宕机，数据还是会丢失。

以上三种策略优缺点总结如下表：

| 策略     | 优点                     | 缺点                             |
| :------- | :----------------------- | :------------------------------- |
| Always   | 可靠性高，数据基本不丢失 | 每个写命令都要落盘，性能影响较大 |
| Everysec | 性能适中                 | 宕机时丢失一秒数据               |
| No       | 性能好                   | 宕机时丢失数据较多               |

#### 2.1.2.日志文件太大怎么办？

随着数据量的增大，AOF日志文件难免会很大，这样将会导致写入和恢复数据都将变得非常慢。此时AOF提供了一种**「重写机制」**解决这一问题。

> 重写机制理解起来很简单，即是`Redis`会创建一个新的`AOF`日志文件，将每个键值对最终的值用一条命令写入日志文件中。

比如读取了键值对`key1:value1`，重写机制会在新的AOF日志文件中记录如下一条命令：

```
set key1 value1
```

其实即是记录多次修改的最终的值记录在新的AOF日志文件中，这样当恢复数据时可直接执行该命令。

**「为什么重写机制能够缩小文件呢？」** 当一个键值被多次修改后，`AOF`日志文件中将会记录多次修改键值的命令，重写机制是根据这个键值最新状态为它生成**「写入」**命令，这样旧文件中的**「多条」**命令在重写后的新日志中变成了**「一条」**命令。

作者画了一张重写流程图，仅供参考，如下：

![image-20210228230239952](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228230239952.png)

AOF重写虽然能够缩减日志文件的大小，达到减少日志记录和数据恢复的时间，但是在数据量非常的大情况下把整个数据库重写后的日志写入磁盘是一个非常耗时的过程，难道不会阻塞主线程吗？

**「答案是：不会阻塞主线程」**；因为AOF重写过程是由后台子进程`bgrewriteaof`来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。

其实重写的过程分为两个阶段：**「一个拷贝，两处日志」**。

**「一个拷贝」**：指每次执行重写时，主线程都`fork`一个子线程`bgrewriteaof`，主线程会把内存数据拷贝一份到子线程，此时子线程中包含了数据库的最新数据。然后子线程就能在不影响主线程的情况下进行AOF重写了。

**「两处日志」**是什么？如下：

1. `第一处日志`：子线程重写并未阻塞主线程，此时主线程仍然会处理请求，此时的AOF日志仍然正在记录着，这样即使宕机了，数据也是齐全的。第一处日志即是值主线程正在使用的日志。
2. `第二处日志`：指新的AOF重写日志；重写过程中的操作也会被写到重写日志缓冲区，这样重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。

> **「总结」**：`Redis`在进行`AOF`重写时，会`fork`一个子线程（不会阻塞主线程）并进行内存拷贝用于重写，然后使用两个日志保证重写过程中，新写入的数据不会丢失。

#### 2.1.3.AOF的缺点

虽说进行了日志重写后，AOF日志文件会缩减很多，但是在数据恢复过程中仍然是一条命令一条命令（由于单线程，只能顺序执行）的执行恢复数据，这个恢复的过程非常缓慢。

#### 2.1.4.AOF总结

AOF这种通过逐一记录操作命令的日志方式，提供了三种写回策略保证数据的可靠性，分别是`Always`、`Everysec`和`No`，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。

为了避免日志文件过大，Redis提供了重写的机制，每次重写都fork一个子线程，拷贝内存数据进行重写，将多条命令缩减成一条生成键值对的命令，最终重写的日志作为新的日志。



### 2.2.方式二：RDB 快照

`RDB`(Redis DataBase)是另外一种持久化方式：内存快照。

> `RDB`记录的是**「某一个时刻」**的内存数据，并不是操作命令。

这种方式类似于拍照，只保留某一时刻的形象。内存快照是将某一时刻的状态以文件的形式写入磁盘。这样即使宕机了，数据也不会丢失，这个快照文件就称为`RDB`文件。

> 由于记录的是某个时刻的内存数据，数据恢复非常快的，不需要像AOF日志逐一执行记录的命令。



#### 2.2.1.给哪些数据做快照？

为了保证数据的可靠性，Redis执行的**「全量快照」**，也就是把内存中的所有数据都写到磁盘中。

随着数据量的增大，一次性把全部数据都写到磁盘中势必会造成线程阻塞，这就关系到Redis的性能了。

针对线程阻塞的问题Redis提供了两个命令，如下：

1. `save`：在主线程中执行，会导致主线程阻塞。
2. `bgsave`：`fork`一个子进程，专门用于写入`RDB`文件，避免了主线程的阻塞，这是Redis的默认配置。

这样就可以使用`bgsave`命令执行全量快照，既可以保证数据的可靠性也避免了主线程的阻塞。



#### 2.2.2.快照时能够修改数据吗？

子线程执行全量快照的同时，主线程仍然在接受着请求，读数据肯定没有问题，但是如果个修改了数据，如何能够保证快照的完整性呢？

**「举个栗子」**：我在`T`时刻进行全量快照，假设数据量有`8G`，写入磁盘的过程至少需要`20S`，在这`20S`的时间内，一旦内存中的数据发生了修改，则快照的完整性就破坏了。

但是如果在快照时不能修改数据，则对Redis的性能有巨大的影响，对于这个问题，Redis是如何解决的呢？

> `Redis`借助操作系统提供的`写时复制技术`（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。

其实很简单，`bgsave`命令会`fork`一个子线程，这个子线程共享所有内存的数据，子线程会读取主线程内存中的数据，将他们写入`RDB`文件。

![640](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/20210228230701.png)

如上图，对于`键值对A`的读取并不会影响子线程，但是如果主线程一旦修改内存中一块数据（例如`键值对D`），这块数据将会被复制一个副本，然后`bgsave`子线程会将其写入`RDB`文件。



#### 2.2.3.多久做一次快照？

快照只是记录某一时刻的数据，一旦时间隔离很久，则服务器一旦宕机，则会丢失那段时间的数据。

比如在`T1`时间做了一次快照，在`T1+t`时又做了一次快照，如果在`t`这个时间段内服务器突然宕机了，则快照中只保存了`T1`时刻的快照，在`t`时间段内的数据修改未被记录（丢失）。如下图：

![image-20210228230749221](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228230749221.png)

从上图明显可以看出，**「`RDB`并不是一个完美的日志记录方案」**，只有让`t`时间逐渐缩小，才能保证丢失的数据缩小。

**「那么问题来了，时间能够缩短`1秒`吗？」** 即是每秒执行一次快照。

> 全量快照是记录某一个时刻的**「全部」**内存数据，每秒执行一次的对Redis性能影响巨大，于是**「增量快照」**就出来了。



#### 2.2.4.增量快照

**「增量快照是指做了一次全量快照之后，后续的快照只对修改的数据进行快照记录」**，这样可以避免每次都全量快照的开销。

增量快照的前提是Redis能够记住修改的数据，这个功能其实开销也是巨大的，需要保存完整的键值对，这对内存的消耗是巨大的。

> 为了解决这个问题，Redis使用了`AOF`和`RDB`混合使用的方式。



### 2.3.AOF和RDB混合使用

这个概念是在`Redis4.0`提出的，简单的说就是**「内存快照以一定的频率执行，比如1小时一次，在两次快照之间，使用AOF日志记录这期间的所有命令操作。」**

> 混合使用的方式使得内存快照不必频繁的执行，并且AOF记录的也不是全部的操作命令，而是两次快照之间的操作命令，不会出现AOF日志文件过大的情况了，避免了AOF重写的开销了。

这个方案既能够用到的RDB的快速恢复的好处，又能享受都只记录操作命令的简单优势，强烈建议使用。

这里的 AOF 日志不再是全量的日志，而是 **自持久化开始到持久化结束** 的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小：

![image-20210228225344786](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228225344786.png)

于是在 Redis 重启的时候，可以先加载 `rdb` 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。

#### 2.3.1.AOF和RDB混合使用总结

`RDB`内存快照记录的是某一个时刻的内存数据，因此能够快速恢复；`AOF`和`RDB`混合使用能够使得宕机后数据快速恢复，又能够避免`AOF`日志文件过大。



## 3.总结

本文介绍了两种数据恢复和持久化的方案，分别是`AOF`和`RDB`。

`AOF`介绍了什么？如下：

1. `AOF`是写后日志，通过记录操作命令持久化数据。
2. 由于`AOF`是在命令执行之后记录日志，如果在写入磁盘之前服务器宕机，则会丢失数据；如果写入磁盘的时候突然阻塞，则会阻塞主线程；为了解决以上问题，AOF机制提供了三种写回的策略，每种策略都有不同的优缺点。
3. `AOF`日志文件过大怎么办？`AOF`通过`fork`一个子线程重写一个新的日志文件（共享主线程的内存，记录最新数据的写入命令），同时子线程重写，避免阻塞主线程。

`RDB`介绍了什么？如下：

1. `RDB`是内存快照，记录某一个时刻的内存数据，而不是操作命令。
2. `Redis`提供了两个命令，分别是`save`、`bgsave`来执行全量快照，这两个命令的区别则是`save`是在主线程执行，势必会阻塞主线程，`bgsave`是在`fork`一个子线程，共享内存。
3. RDB通过操作系统的**「写时复制技术」**，能够保证在执行快照的同时主线程能够修改快照。
4. 由于两次快照之间是存在间隔的，一旦服务器宕机，则会丢失两次间隔时刻的数据，`Redis4.0`开始使用`AOF`日志记录两次快照之间执行的命令（`AOF`和`RDB`混合使用）。



## 4.应用

### 4.1.简单了解一下Redis企业级数据备份方案

#### 4.1.1.企业级的持久化的配置策略

------

1. 每隔1分钟去检查如果超过10000个可以变更，则生成一个快照。RDB最多丢1分钟的数据。

```
Copysave 60 10000
```

2. AOF一定要打开，fsync，everysec

```properties
Copy#就是当前AOF大小膨胀到超过上次100%，上次的两倍
auto-aof-rewrite-percentage 100
#最小触发size
auto-aof-rewrite-min-size 64mb
```

 

#### 4.1.2.企业级的数据备份方案

------

> RDB非常适合做冷备，每次生成之后，就不会再有修改了

##### 4.1.2.1.数据备份方案

1. 写一个linux服务器的crontab命令定时调度脚本去做数据备份
2. 每小时都copy一份rdb的备份，到一个目录中去，仅仅保留最近48小时的备份
3. 每天都保留一份当日的rdb的备份，到一个目录中去，仅仅保留最近1个月的备份
4. 每次copy备份的时候，都把太旧的备份给删了
5. 每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去

 

- **每小时copy一次备份，删除48小时前的数据**

  ```
  Copycrontab -e
  
  0 * * * * sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh
  
  redis_rdb_copy_hourly.sh
  
  #!/bin/sh
  
  cur_date=`date +%Y%m%d%k`
  rm -rf /usr/local/redis/snapshotting/$cur_date
  mkdir /usr/local/redis/snapshotting/$cur_date
  cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date
  
  del_date=`date -d -48hour +%Y%m%d%k`
  rm -rf /usr/local/redis/snapshotting/$del_date
  ```

  

- **每天copy一次备份**

  ```
  Copycrontab -e
  
  0 0 * * * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh
  
  redis_rdb_copy_daily.sh
  
  #!/bin/sh
  
  cur_date=`date +%Y%m%d`
  rm -rf /usr/local/redis/snapshotting/$cur_date
  mkdir /usr/local/redis/snapshotting/$cur_date
  cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date
  
  del_date=`date -d -1month +%Y%m%d`
  rm -rf /usr/local/redis/snapshotting/$del_date
  ```

  

- **每天一次将所有数据上传一次到远程的云服务器上去**


 

#### 4.1.3.数据恢复方案

------

1. 如果是redis进程挂掉，那么重启redis进程即可，直接基于AOF日志文件恢复数据
2. 如果是redis进程所在机器挂掉，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复，AOF append-only，顺序写入，如果AOF文件破损，那么用redis-check-aof fix
3. 如果redis当前最新的AOF和RDB文件出现了丢失/损坏，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复
4. 如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照回来恢复数据
5. 如果是发现有重大的数据错误，比如某个小时上线的程序一下子将数据全部污染了，数据全错了，那么可以选择某个更早的时间点，对数据进行恢复

*举个例子，12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了
找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据，不就可以了吗*



#### 4.1.4.容灾演练

------

- **场景**：

  我们希望redis数据恢复到某一个时间点，所以选择那个时间点的RDB文件进行恢复，我们拷贝RDB到服务器中。把原来的aof文件删掉。

  *注意：我们此时使用的是混合持久化机制。会优先用AOF文件去恢复数据，但是我们发现redis自动生成的appendonly.aof是没有数据的，而我们拷贝的dump.rdb是有数据的。*

- **错误操作**

  redis启动，会自动生成一个空的AOF文件，并使用这个空的AOF恢复数据，又自动重新基于内存的数据生成了一份最新的空的rdb快照，覆盖掉了我们有数据的拷贝过去的那份dump.rdb

- **原因分析**

  虽然你删除了appendonly.aof，但是因为打开了aof持久化，redis启动就一定会优先基于aof去恢复，即使文件不在，那就创建一个新的空的aof文件，导致redis恢复后又是空的，又生成了一个空的RDB文件，结果数据恢复失败了。

- **调整操作**：

  停止redis，应该先暂时在配置中关闭aof，然后拷贝一份rdb过来，再重启redis，数据就会使用RDB进行数据恢复，可以恢复过来，这一步是对的

  如果此时脑子一热，再关掉redis，手动修改配置文件，打开aof，再重启redis，数据又没了，空的aof文件，所有数据又没了。

- **最终正确操作**

  在数据安全丢失的情况下，基于rdb冷备如何完美的恢复数据，同时还保持aof和rdb的双开

  - 停止redis，配置关闭aof，拷贝rdb备份，重启redis，确认数据恢复，直接在命令行热修改redis配置，打开aof，这个redis就会将内存中的数据对应的日志，写入aof文件中。此时aof和rdb两份数据文件的数据就同步了

    ```
    Copy#使用命令打开AOF
    redis-cli config set appendonly yes
    ```
    
  - redis config set热修改配置参数，可是配置文件中的实际的参数没有被持久化的修改，再次停止redis，手动修改配置文件，打开aof的命令，再次重启redis，完美！









