[toc]



# Redis 面试题



## 你知道Redis的字符串是怎么实现的吗？

Redis是C语言开发的，C语言自己就有字符类型，但是Redis却没直接采用C语言的字符串类型，而是自己构建了`动态字符串（SDS）`的抽象类型。

![image-20210228181856863](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228181856863.png)

就好比这样的一个命令，其实我是在Redis创建了两个SDS，一个是名为`aobing`的Key SDS，另一个是名为`cool`的Value SDS，就算是字符类型的List，也是由很多的SDS构成的Key和Value罢了。

SDS在Redis中除了用作字符串，还用作缓冲区（buffer），那到这里大家都还是有点疑惑的，C语言的字符串不好么为啥用SDS？SDS长啥样？有什么优点呢?

为此我去找到了Redis的源码，可以看到SDS值的结果大概是这样的，源码的在GitHub上是开源的大家一搜就有了。

```c
struct sdshdr{
 int len;
 int free;
 char buf[];
}
```

![image-20210228182032831](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182032831.png)

回到最初的问题，为什么Redis用了自己新开发的SDS，而不用C语言的字符串？那好我们去看看他们的区别。



### SDS与C字符串的区别

1. **计数方式不同**

   C语言对字符串长度的统计，就完全来自遍历，从头遍历到末尾，直到发现空字符就停止，以此统计出字符串的长度，这样获取长度的时间复杂度来说是0（n），大概就像下面这样：

   ![](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/20210228182201.gif)

   但是这样的计数方式会留下隐患，所以Redis没有采用C的字符串，我后面会提到。

   而Redis我在上面已经给大家看过结构了，他自己本身就保存了长度的信息，所以我们获取长度的时间复杂度为0（1），是不是发现了Redis快的一点小细节了？还没完，不止这些。

2. **杜绝缓冲区溢出**

   字符串拼接是我们经常做的操作，在C和Redis中一样，也是很常见的操作，但是问题就来了，C是不记录字符串长度的，一旦我们调用了拼接的函数，如果没有提前计算好内存，是会产生缓存区溢出的。

   比如本来字符串长这样：

   ![image-20210228182336698](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182336698.png)

   你现在需要在后面拼接  ，但是你没计算好内存，结果就可能这样了：

   ![image-20210228182425120](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182425120.png)

   这是你要的结果么？很显然，不是，你的结果意外的被修改了，这要是放在线上的系统，这不是完了？那Redis是怎么避免这样的情况的？

   我们都知道，他结构存储了当前长度，还有free未使用的长度，那简单呀，你现在做了拼接操作，我去判断一些是否可以放得下，如果长度够就直接执行，如果不够，那我就进行扩容。

   这些大家在Redis源码里面都是可以看到对应的API的，后面我就不一一贴源码了，有兴趣的可以自己去看一波，需要一点C语言的基础。

   ![640 (2)](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/20210228182501.webp)

3. **减少修改字符串时带来的内存重分配次数**

   C语言字符串底层也是一个数组，每次创建的时候就创建一个N+1长度的字符，多的那个1，就是为了保存空字符的，这个空字符也是个坑，但是不是这个环节探讨的内容。

   Redis是个高速缓存数据库，如果我们需要对字符串进行频繁的拼接和截断操作，如果我们写代码忘记了重新分配内存，就可能造成缓冲区溢出，以及内存泄露。

   内存分配算法很耗时，且不说你会不会忘记重新分配内存，就算你全部记得，对于一个高速缓存数据库来说，这样的开销也是我们应该要避免的。

   Redis为了避免C字符串这样的缺陷，就分别采用了两种解决方案，去达到性能最大化，空间利用最大化：

   - **空间预分配**：当我们对SDS进行扩展操作的时候，Redis会为SDS分配好内存，并且根据特定的公式，分配多余的free空间，还有多余的1byte空间（这1byte也是为了存空字符），这样就可以避免我们连续执行字符串添加所带来的内存分配消耗。

     比如现在有这样的一个字符：

     ![image-20210228182720875](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182720875.png)

     我们调用了拼接函数，字符串边长了，Redis还会根据算法计算出一个free值给他备用：

     ![image-20210228182737393](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182737393.png)

     我们再继续拼接，你会发现，备用的free用上了，省去了这次的内存重分配：

     ![image-20210228182753421](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182753421.png)

   - **惰性空间释放**：刚才提到了会预分配多余的空间，很多小伙伴会担心带来内存的泄露或者浪费，别担心，Redis大佬一样帮我们想到了，当我们执行完一个字符串缩减的操作，redis并不会马上收回我们的空间，因为可以预防你继续添加的操作，这样可以减少分配空间带来的消耗，但是当你再次操作还是没用到多余空间的时候，Redis也还是会收回对于的空间，防止内存的浪费的。

     还是一样的字符串：

     ![image-20210228182847778](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182847778.png)

     当我们调用了删减的函数，并不会马上释放掉free空间：

     ![image-20210228182905523](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182905523.png)

     如果我们需要继续添加这个空间就能用上了，减少了内存的重分配，如果空间不需要了，调用函数删掉就好了：

     ![image-20210228182924321](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228182924321.png)

4. **二进制安全**

   仔细看的仔肯定看到上面我不止一次提到了空字符也就是’\0‘，C语言是判断空字符去判断一个字符的长度的，但是有很多数据结构经常会穿插空字符在中间，比如图片，音频，视频，压缩文件的二进制数据，就比如下面这个单词，他只能识别前面的 不能识别后面的字符，那对于我们开发者而言，这样的结果显然不是我们想要的对不对。

   ![image-20210228183010653](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228183010653.png)

   Redis就不存在这个问题了，他不是保存了字符串的长度嘛，他不判断空字符，他就判断长度对不对就好了，所以redis也经常被我们拿来保存各种二进制数据，我反正是用的很high，经常用来保存小文件的二进制。

   ![image-20210228183037288](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210228183037288.png)

### 总结

大家是不是发现，一个小小的SDS居然有这么多道理在这？

以前就知道Redis快，最多说个Redis是单线程的，说个多路IO复用，说个基于内存的操作就完了，现在是不是还可以展开说说了？





## Redis中是如何实现分布式锁的？

分布式锁常见的三种实现方式：

1. 数据库乐观锁；
2. 基于Redis的分布式锁；
3. 基于ZooKeeper的分布式锁。

本地面试考点是，你对Redis使用熟悉吗？Redis中是如何实现分布式锁的。

### 要点

Redis要实现分布式锁，以下条件应该得到满足

**互斥性**

- 在任意时刻，只有一个客户端能持有锁。

**不能死锁**

- 客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。

**容错性**

- 只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。



### 实现

可以直接通过 `set key value px milliseconds nx` 命令实现加锁， 通过Lua脚本实现解锁。

```
//获取锁（unique_value可以是UUID等）
SET resource_name unique_value NX PX  30000

//释放锁（lua脚本中，一定要比较value，防止误解锁）
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

**代码解释**

- set 命令要用 `set key value px milliseconds nx`，替代 `setnx + expire` 需要分两次执行命令的方式，保证了原子性，
- value 要具有唯一性，可以使用`UUID.randomUUID().toString()`方法生成，用来标识这把锁是属于哪个请求加的，在解锁的时候就可以有依据；
- 释放锁时要验证 value 值，防止误解锁；
- 通过 Lua 脚本来避免 Check And Set 模型的并发问题，因为在释放锁的时候因为涉及到多个Redis操作 （利用了eval命令执行Lua脚本的原子性）；

**加锁代码分析**

首先，`set()`加入了NX参数，可以保证如果已有`key`存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。最后，因为我们将value赋值为requestId，用来标识这把锁是属于哪个请求加的，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。

**解锁代码分析**

将`Lua`代码传到`jedis.eval()`方法里，并使参数`KEYS[1]`赋值为`lockKey`，`ARGV[1]`赋值为`requestId`。在执行的时候，首先会获取锁对应的`value`值，检查是否与`requestId`相等，如果相等则解锁（删除key）。

**存在的风险**

如果存储锁对应key的那个节点挂了的话，就可能存在丢失锁的风险，导致出现多个客户端持有锁的情况，这样就不能实现资源的独享了。

1. 客户端A从master获取到锁
2. 在master将锁同步到slave之前，master宕掉了（Redis的主从同步通常是异步的）。
   主从切换，slave节点被晋级为master节点
3. 客户端B取得了同一个资源被客户端A已经获取到的另外一个锁。导致存在同一时刻存不止一个线程获取到锁的情况。



### redlock算法出现

这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把锁：

1. 获取当前时间戳，单位是毫秒；
2. 跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；
3. 尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1；
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。

 ![image-20210304231419219](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210304231419219.png)

Redis 官方给出了以上两种基于 Redis 实现分布式锁的方法，详细说明可以查看：

> https://redis.io/topics/distlock 。



### Redisson实现

Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还实现了可重入锁（Reentrant Lock）、公平锁（Fair Lock、联锁（MultiLock）、 红锁（RedLock）、 读写锁（ReadWriteLock）等，还提供了许多分布式服务。

Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。

**Redisson 分布式重入锁用法**

Redisson 支持单点模式、主从模式、哨兵模式、集群模式，这里以单点模式为例：

```
// 1.构造redisson实现分布式锁必要的Config
Config config = new Config();
config.useSingleServer().setAddress("redis://127.0.0.1:5379").setPassword("123456").setDatabase(0);
// 2.构造RedissonClient
RedissonClient redissonClient = Redisson.create(config);
// 3.获取锁对象实例（无法保证是按线程的顺序获取到）
RLock rLock = redissonClient.getLock(lockKey);
try {
    /**
     * 4.尝试获取锁
     * waitTimeout 尝试获取锁的最大等待时间，超过这个值，则认为获取锁失败
     * leaseTime   锁的持有时间,超过这个时间锁会自动失效（值应设置为大于业务处理的时间，确保在锁有效期内业务能处理完）
     */
    boolean res = rLock.tryLock((long)waitTimeout, (long)leaseTime, TimeUnit.SECONDS);
    if (res) {
        //成功获得锁，在这里处理业务
    }
} catch (Exception e) {
    throw new RuntimeException("aquire lock fail");
}finally{
    //无论如何, 最后都要解锁
    rLock.unlock();
}
```

**加锁流程图**

![image-20210304231636699](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210304231636699.png)

**解锁流程图**

![image-20210304231719590](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210304231719590.png)

我们可以看到，RedissonLock是可重入的，并且考虑了失败重试，可以设置锁的最大等待时间， 在实现上也做了一些优化，减少了无效的锁申请，提升了资源的利用率。

需要特别注意的是，RedissonLock 同样没有解决 节点挂掉的时候，存在丢失锁的风险的问题。而现实情况是有一些场景无法容忍的，所以 Redisson 提供了实现了redlock算法的 RedissonRedLock，RedissonRedLock 真正解决了单点失败的问题，代价是需要额外的为 RedissonRedLock 搭建Redis环境。

所以，如果业务场景可以容忍这种小概率的错误，则推荐使用 RedissonLock， 如果无法容忍，则推荐使用 RedissonRedLock。





## redis 为什么是单线程的？
因为CPU不是Redis的瓶颈。Redis的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了。关于redis的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求，参见：How fast is Redis?

如果万一CPU成为你的Redis瓶颈了，或者，你就是不想让服务器其他核闲置，那怎么办？

那也很简单，你多起几个Redis进程就好了。Redis是keyvalue数据库，又不是关系数据库，数据之间没有约束。只要客户端分清哪些key放在哪个Redis进程上就可以了。redis-cluster可以帮你做的更好。

单线程可以处理高并发请求吗？

当然可以了，Redis都实现了。

有一点概念需要澄清，并发并不是并行。

（相关概念：并发性I/O流，意味着能够让一个计算单元来处理来自多个客户端的流请求。并行性，意味着服务器能够同时执行几个事情，具有多个计算单元）

Redis总体快速的原因：

采用队列模式将并发访问变为串行访问（？）

单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），其他模块仍用了多个线程。

总体来说快速的原因如下：
1. 绝大部分请求是纯粹的内存操作（非常快速）
1. 采用单线程,避免了不必要的上下文切换和竞争条件
1. 非阻塞IO

内部实现采用epoll，采用了epoll+自己实现的简单的事件框架。epoll中的读、写、关闭、连接都转化成了事件，然后利用epoll的多路复用特性，绝不在io上浪费一点时间

这3个条件不是相互独立的，特别是第一条，如果请求都是耗时的，采用单线程吞吐量及性能可想而知了。应该说redis为特殊的场景选择了合适的技术方案。



## jedis 和 redisson 有哪些区别？

### 概述
本文的主要内容为对比Redis的两个框架：Jedis与Redisson，分析各自的优势与缺点，为项目中Java缓存方案中的Redis编程模型的选择提供参考。

### Jedis与Redisson对比
#### 概况对比
Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。
#### 编程模型
Jedis中的方法调用是比较底层的暴露的Redis的API，也即Jedis中的Java方法基本和Redis的API保持着一致，了解Redis的API，也就能熟练的使用Jedis。而Redisson中的方法则是进行比较高的抽象，每个方法调用可能进行了一个或多个Redis方法调用。

如下分别为Jedis和Redisson操作的简单示例：

Jedis设置key-value与set操作：
Jedis jedis = …;
jedis.set("key", "value");
List<String> values = jedis.mget("key", "key2", "key3");

Redisson操作map：
Redisson redisson = …
RMap map = redisson.getMap("my-map"); // implement java.util.Map
map.put("key", "value");
map.containsKey("key");
map.get("key");

#### 可伸缩性
Jedis使用阻塞的I/O，且其方法调用都是同步的，程序流需要等到sockets处理完I/O才能执行，不支持异步。Jedis客户端实例不是线程安全的，所以需要通过连接池来使用Jedis。
Redisson使用非阻塞的I/O和基于Netty框架的事件驱动的通信层，其方法调用是异步的。Redisson的API是线程安全的，所以可以操作单个Redisson连接来完成各种操作。

#### 数据结构
Jedis仅支持基本的数据类型如：String、Hash、List、Set、Sorted Set。
Redisson不仅提供了一系列的分布式Java常用对象，基本可以与Java的基本数据结构通用，还提供了许多分布式服务，其中包括（BitSet, Set, Multimap, SortedSet, Map, List, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, AtomicLong, CountDownLatch, Publish / Subscribe, Bloom filter, Remote service, Spring cache, Executor service, Live Object service, Scheduler service）。

在分布式开发中，Redisson可提供更便捷的方法。

#### 第三方框架整合
1. Redisson提供了和Spring框架的各项特性类似的，以Spring XML的命名空间的方式配置RedissonClient实例和它所支持的所有对象和服务；
2. Redisson完整的实现了Spring框架里的缓存机制；
3. Redisson在Redis的基础上实现了Java缓存标准规范；
4. Redisson为Apache Tomcat集群提供了基于Redis的非黏性会话管理功能。该功能支持Apache Tomcat的6、7和8版。
5. Redisson还提供了Spring Session会话管理器的实现。



## Redis 与 Memcached 相比有哪些优势？

之前也用过redis，当时是用来存储一些热数据，量也不大，但是操作很频繁。现在项目中用的是MongoDB，目前是百万级的数据，将来会有千万级、亿级。

就Redis和MongoDB来说，大家一般称之为Redis缓存、MongoDB数据库。这也是有道有理有根据的，Redis主要把数据存储在内存中，其“缓存”的性质远大于其“数据存储“的性质，其中数据的增删改查也只是像变量操作一样简单；

MongoDB却是一个“存储数据”的系统，增删改查可以添加很多条件，就像SQL数据库一样灵活，这一点在面试的时候很受用。

MongoDB语法与现有关系型数据库SQL语法比较

> https://www.cnblogs.com/java-spring/p/9488200.html

**Mongodb与Redis应用指标对比**

![640](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/20210305220101.webp)



## Redis是单线程的吗？

Redis是单线程的，这话搁以前，是横着走的，谁都知道的真理。现在不一样，Redis 变了。再说这句话，多少得有质疑的语气来跟你辩驳一番。意志不坚定的，可能就缴械投降，顺着别人走了。

到底是什么样的，各位看官请跟小莱一起往下看：

![image-20210306101637984](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306101637984.png)



### Reactor模式

反应器模式，你可能不太认识，如果看过上篇文章的话应该会有点印象。涉及到 Redis 线程它是一个绕不过去的话题。

**1、传统阻塞IO模型**

在讲反应器模式前，这里有必要提一下传统阻塞IO模型的处理方式。

在传统阻塞IO模型中，由一个独立的 Acceptor 线程来监听客户端的连接，每当有客户端请求过来时，它就会为客户端分配一个新的线程来进行处理。当同时有多个请求过来，服务端对应的就会分配相应数量的线程。这就会导致CPU频繁切换，浪费资源。

有的连接请求过来不做任何事情，但服务端还会分配对应的线程，这样就会造成不必要的线程开销。这就好比你去餐厅吃饭，你拿着菜单看了半天发现真他娘的贵，然后你就走人了。这段时间等你点菜的服务员就相当于一个对应的线程，你要点菜可以看作一个连接请求。

![image-20210306101722407](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306101722407.png)

同时，每次建立连接后，当线程调用读写方法时，线程会被阻塞，直到有数据可读可写， 在此期间线程不能做其它事情。还是上边餐厅吃饭的例子，你出去转了一圈发现还是这家性价比最高。回到这家餐厅又拿着菜单看了半天，服务员也在旁边等你点完菜为止。这个过程中服务员什么也不能做，只能这么干等着，这个过程相当于阻塞。

![image-20210306101751141](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306101751141.png)

你看这样的方式，每来一个请求就要分配一个线程，并且还得阻塞地等线程处理完。有的请求还只是过来连接下，什么操作也不干，还得为它分配一个线程，对服务器资源要求那得多高啊。遇到高并发场景，不敢想象。对于连接数目比较小的的固定架构倒是可以考虑。



**2、伪异步IO模型**

你可能了解过一种通过线程池优化的解决方案，采用线程池和任务队列的方式。这种被称作伪异步IO模型。

当有客户端接入时，将客户端的请求封装成一个 task 投递到后端线程池中来处理。线程池维护一个消息队列和多个活跃线程，对消息队列中的任务进行处理。

![image-20210306101816405](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306101816405.png)

这种解决方案，避免了为每个请求创建一个线程导致的线程资源耗尽问题。但是底层仍然是同步阻塞模型。如果线程池内的所有线程都阻塞了，那么对于更多请求就无法响应了。因此这种模式会限制最大连接数，并不能从根本上解决问题。

我们继续用上边的餐厅来举例，餐厅老板在经营了一段时间后，顾客多了起来，原本店里的5个服务员一对一服务的话根本对付不过来。于是老板采用5个人线程池的方式。服务员服务完一个客人后立刻去服务另一个。

这时问题出现了，有的客人点菜特别慢，服务员就得等待很长时间，直到客人点完为止。如果5个客人都点的特别慢的话，这5个服务员就得一直等下去，就会导致其余的顾客没有人服务的状态。这就是我们上边所说的线程池所有线程都被阻塞的情况。

那么这种问题该如何解决呢？别急， Reactor 模式就要出场了。



**3、Reactor设计模式**

Reactor 模式的基本设计思想是基于I/O复用模型来实现的。

这里说下I/O复用模型。和传统IO多线程阻塞不同，I/O复用模型中多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理。

什么意思呢？餐厅老板也发现了顾客点餐慢的问题，于是他采用了一种大胆的方式，只留了一个服务员。当客人点餐的时候，这个服务员就去招待别的客人，客人点好餐后直接喊服务员来进行服务。这里的顾客和服务员可以分别看作多个连接和一个线程。服务员阻塞在一个顾客那里，当有别的顾客点好餐后，她就立刻去服务其他的顾客。

了解了 reactor 的设计思想后，我们再来看下今天的主角单 reactor 单线程的实现方案：

![image-20210306101906932](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306101906932.png)

Reactor 通过 I/O复用程序监控客户端请求事件，收到事件后通过任务分派器进行分发。

针对建立连接请求事件，通过 Acceptor 处理，并建立对应的 handler 负责后续业务处理。

针对非接事件，Reactor 会调用对应的 handler 完成 read->业务处理->write 处理流程，并将结果返回给客户端。

整个过程都在一个线程里完成。

![image-20210306101938575](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306101938575.png)

### 单线程时代

了解了 Reactor 模式后，你可能会有一个疑问，这个和我们今天的主题有什么关系呢。可能你不知道的是，Redis 是基于 Reactor 单线程模式来实现的。

IO多路复用程序接收到用户的请求后，全部推送到一个队列里，交给文件分派器。对于后续的操作，和在 reactor 单线程实现方案里看到的一样，整个过程都在一个线程里完成，因此 Redis 被称为是单线程的操作。

![image-20210306102027546](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306102027546.png)

对于单线程的 Redis 来说，基于内存，且命令操作时间复杂度低，因此读写速率是非常快的。



### 多线程时代

Redis6 版本中引入了多线程。上边已经提到过 Redis 单线程处理有着很快的速度，那为什么还要引入多线程呢？单线程的瓶颈在什么地方？

我们先来看第二个问题，在 Redis 中，单线程的性能瓶颈主要在网络IO操作上。也就是在读写网络 read/write 系统调用执行期间会占用大部分 CPU 时间。如果你要对一些大的键值对进行删除操作的话，在短时间内是删不完的，那么对于单线程来说就会阻塞后边的操作。

回想下上边讲得 Reactor 模式中单线程的处理方式。针对非连接事件，Reactor 会调用对应的 handler 完成 read->业务处理->write 处理流程，也就是说这一步会造成性能上的瓶颈。

Redis 在设计上采用将网络数据读写和协议解析通过多线程的方式来处理，对于命令执行来说，仍然使用单线程操作。



### 总结

**Reactor模式**

- 传统阻塞IO模型客户端与服务端线程1:1分配，不利于进行扩展。
- 伪异步IO模型采用线程池方式，但是底层仍然使用同步阻塞方式，限制了最大连接数。
- Reactor 通过 I/O复用程序监控客户端请求事件，通过任务分派器进行分发。

**单线程时代**

- 基于 Reactor 单线程模式实现，通过IO多路复用程序接收到用户的请求后，全部推送到一个队列里，交给文件分派器进行处理。

**多线程时代**

- 单线程性能瓶颈主要在网络IO上。
- 将网络数据读写和协议解析通过多线程的方式来处理 ，对于命令执行来说，仍然使用单线程操作。



## 熟悉Redis吗，项目中你是如何对Redis内存进行优化的

对于redis来说，什么是最重要的？

毋庸置疑，是内存。

### 一、reids 内存分析

redis内存使用情况：info memory

![640](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/20210306103601.webp)

示例：

![image-20210306103727186](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306103727186.png)

可以看到，当前节点内存碎片率为`226893824/209522728≈1.08`，使用的内存分配器是jemalloc。

`used_memory_rss` 通常情况下是大于 `used_memory` 的，因为内存碎片的存在。

但是当操作系统把redis内存swap到硬盘时，memory_fragmentation_ratio 会小于1。redis使用硬盘作为内存，因为硬盘的速度，redis性能会受到极大的影响。



### 二、redis 内存使用

之前的文章 关于redis，你需要了解的几点！中我们简单介绍过redis的内存使用分布：自身内存，键值对象占用、缓冲区内存占用及内存碎片占用。

> https://www.cnblogs.com/niejunlei/p/12896605.html

redis 空进程自身消耗非常的少，可以忽略不计，优化内存可以不考虑此处的因素。

**1、对象内存**

对象内存，也即真实存储的数据所占用的内存。

redis k-v结构存储，对象占用可以简单的理解为 `k-size + v-size`。

redis的键统一都为字符串类型，值包含多种类型：string、list、hash、set、zset五种基本类型及基于string的Bitmaps和HyperLogLog类型等。

在实际的应用中，一定要做好kv的构建形式及内存使用预期，可以参考 关于redis，你需要了解的几点！中关于不同值类型不同形式下的内部存储实现介绍。

**2、缓冲内存**

缓冲内存包括三部分：客户端缓存、复制积压缓存及AOF缓冲区。

**2.1 客户端缓存**

接入redis服务器的TCP连接输入输出缓冲内存占用，TCP输入缓冲占用是不受控制的，最大允许空间为1G。输出缓冲占用可以通过`client-output-buffer-limit`参数配置。

**redis 客户端主要分为从客户端、订阅客户端和普通客户端。**

**从客户端连接占用：**也就是我们所说的slave，主节点会为每一个从节点建立一条连接用于命令复制，缓冲配置为：`client-output-buffer-limit slave 256mb 64mb 60`。

主从之间的间络延迟及挂载的从节点数量是影响内存占用的主要因素。因此在涉及需要异地部署主从时要特别注意，另外，也要避免主节点上挂载过多的从节点（<=2）；

**订阅客户端内存占用：**发布订阅功能连接客户端使用单独的缓冲区，默认配置：`client-output-buffer-limit pubsub 32mb 8mb 60`。

当消费慢于生产时会造成缓冲区积压，因此需要特别注意消费者角色配比及生产、消费速度的监控。

普通客户端内存占用：除了上述之外的其它客户端，如我们通常的应用连接，默认配置：`client-output-buffer-limit normal 1000`。

可以看到，普通客户端没有配置缓冲区限制，通常一般的客户端内存消耗也可以忽略不计。

但是当redis服务器响应较慢时，容易造成大量的慢连接，主要表现为连接数的突增，如果不能及时处理，此时会严重影响redis服务节点的服务及恢复。

关于此，在实际应用中需要注意几点：

- maxclients最大连接数配置必不可少。
- 合理预估单次操作数据量（写或读）及网络时延ttl。
- 禁止线上大吞吐量命令操作，如keys等。

高并发应用情景下，redis内存使用需要有实时的监控预警机制，

**2.2 复制积压缓冲区**

v2.8之后提供的一个可重用的固定大小缓冲区，用以实现向从节点的部分复制功能，避免全量复制。配置单数：`repl-backlog-size`，默认1M。单个主节点配置一个复制积压缓冲区。

**2.3 AOF缓冲区**

AOF重写期间增量的写入命令保存，此部分缓存占用大小取决于AOF重写时间及增量。

**3、内存碎片内存占用**

关于redis，你需要了解的几点！简单介绍过redis的内存分配方式。（更多面试题，欢迎关注公众号 Java面试题精选）



### 三、redis 子进程内存消耗

子进程即redis执行持久化（RDB/AOF）时fork的子任务进程。

**1、关于linux系统的写时复制机制：**

父子进程会共享相同的物理内存页，父进程处理写请求时会对需要修改的页复制一份副本进行修改，子进程读取的内存则为fork时的父进程内存快照，因此，子进程的内存消耗由期间的写操作增量决定。

**2、关于linux的透明大页机制THP（Transparent Huge Page）：**

THP机制会降低fork子进程的速度；写时复制内存页由4KB增大至2M。高并发情境下，写时复制内存占用消耗影响会很大，因此需要选择性关闭。

**3、关于linux配置：**

一般需要配置linux系统 `vm.overcommit_memory=1`，以允许系统可以分配所有的物理内存。防止fork任务因内存而失败。



### 四、redis 内存管理

redis的内存管理主要分为两方面：内存上限控制及内存回收管理。

**1、内存上限：maxmemory**

目的：缓存应用内存回收机制触发 + 防止物理内存用尽（redis 默认无限使用服务器内存） + 服务节点内存隔离（单服务器上部署多个redis服务节点）

在进行内存分配及限制时要充分考虑内存碎片占用影响。

动态调整，扩展redis服务节点可用内存：`config set maxmemory {}`。

**2、内存回收**

回收时机：键过期、内存占用达到上限

**2.1 过期键删除：**

redis 键过期时间保存在内部的过期字典中，redis采用惰性删除机制+定时任务删除机制。

**惰性删除：**即读时删除，读取带有超时属性的键时，如果键已过期，则删除然后返回空值。这种方式存在问题是，触发时机，加入过期键长时间未被读取，那么它将会一直存在内存中，造成内存泄漏。

**定时任务删除：**redis内部维护了一个定时任务（默认每秒10次，可配置），通过自适应法进行删除。

删除逻辑如下：

![640 (1)](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/20210306103801.webp)

> 需要说明的一点是，快慢模式执行的删除逻辑相同，这是超时时间不同。

**2.2 内存溢出控制**

当内存达到maxmemory，会触发内存回收策略，具体策略依据maxmemory-policy来执行。

- noevication：默认不回收，达到内存上限，则不再接受写操作，并返回错误。
- volatile-lru：根据LRU算法删除设置了过期时间的键，如果没有则不执行回收。
- allkeys-lru：根据LRU算法删除键，针对所有键。
- allkeys-random：随机删除键。
- volatitle-random：速记删除设置了过期时间的键。
- volatilte-ttl：根据键ttl，删除最近过期的键，同样如果没有设置过期的键，则不执行删除。

动态配置：`config set maxmemory-policy {}`

在设置了maxmemory情况下，每次的redis操作都会检查执行内存回收，因此对于线上环境，要确保所这只的`maxmemory>used_memory`。

另外，可以通过动态配置maxmemory来主动触发内存回收。



## 你的Redis为什么变慢了？

Redis作为内存数据库，拥有非常高的性能，单个实例的QPS能够达到10W左右。但我们在使用Redis时，经常时不时会出现访问延迟很大的情况，如果你不知道Redis的内部实现原理，在排查问题时就会一头雾水。

很多时候，Redis出现访问延迟变大，都与我们的使用不当或运维不合理导致的。

这篇文章我们就来分析一下Redis在使用过程中，经常会遇到的延迟问题以及如何定位和分析。

### 使用复杂度高的命令

如果在使用Redis时，发现访问延迟突然增大，如何进行排查？

首先，第一步，建议你去查看一下Redis的慢日志。Redis提供了慢日志命令的统计功能，我们通过以下设置，就可以查看有哪些命令在执行时延迟比较大。

首先设置Redis的慢日志阈值，只有超过阈值的命令才会被记录，这里的单位是微妙，例如设置慢日志的阈值为5毫秒，同时设置只保留最近1000条慢日志记录：

```
# 命令执行超过5毫秒记录慢日志
CONFIG SET slowlog-log-slower-than 5000
# 只保留最近1000条慢日志
CONFIG SET slowlog-max-len 1000
```

设置完成之后，所有执行的命令如果延迟大于5毫秒，都会被Redis记录下来，我们执行`SLOWLOG get 5`查询最近5条慢日志：

```
127.0.0.1:6379> SLOWLOG get 5
1) 1) (integer) 32693       # 慢日志ID
   2) (integer) 1593763337  # 执行时间
   3) (integer) 5299        # 执行耗时(微妙)
   4) 1) "LRANGE"           # 具体执行的命令和参数
      2) "user_list_2000"
      3) "0"
      4) "-1"
2) 1) (integer) 32692
   2) (integer) 1593763337
   3) (integer) 5044
   4) 1) "GET"
      2) "book_price_1000"
...
```

通过查看慢日志记录，我们就可以知道在什么时间执行哪些命令比较耗时，如果你的业务**经常使用`O(n)`以上复杂度的命令**，例如`sort`、`sunion`、`zunionstore`，或者在执行`O(n)`命令时操作的数据量比较大，这些情况下Redis处理数据时就会很耗时。

如果你的服务请求量并不大，但Redis实例的CPU使用率很高，很有可能是使用了复杂度高的命令导致的。

解决方案就是，不使用这些复杂度较高的命令，并且一次不要获取太多的数据，每次尽量操作少量的数据，让Redis可以及时处理返回。

### 存储大key

如果查询慢日志发现，并不是复杂度较高的命令导致的，例如都是`SET`、`DELETE`操作出现在慢日志记录中，那么你就要怀疑是否存在Redis写入了大key的情况。

Redis在写入数据时，需要为新的数据分配内存，当从Redis中删除数据时，它会释放对应的内存空间。

如果一个key写入的数据非常大，Redis在**分配内存时也会比较耗时**。同样的，当删除这个key的数据时，**释放内存也会耗时比较久**。

你需要检查你的业务代码，是否存在写入大key的情况，需要评估写入数据量的大小，业务层应该避免一个key存入过大的数据量。

那么有没有什么办法可以扫描现在Redis中是否存在大key的数据吗？

Redis也提供了扫描大key的方法：

```
redis-cli -h $host -p $port --bigkeys -i 0.01
```

使用上面的命令就可以扫描出整个实例key大小的分布情况，它是以类型维度来展示的。

需要注意的是当我们在线上实例进行大key扫描时，Redis的QPS会突增，为了降低扫描过程中对Redis的影响，我们需要控制扫描的频率，使用`-i`参数控制即可，它表示扫描过程中每次扫描的时间间隔，单位是秒。

使用这个命令的原理，其实就是Redis在内部执行`scan`命令，遍历所有key，然后针对不同类型的key执行`strlen`、`llen`、`hlen`、`scard`、`zcard`来获取字符串的长度以及容器类型(list/dict/set/zset)的元素个数。

而对于容器类型的key，只能扫描出元素最多的key，但元素最多的key不一定占用内存最多，这一点需要我们注意下。不过使用这个命令一般我们是可以对整个实例中key的分布情况有比较清晰的了解。

针对大key的问题，Redis官方在4.0版本推出了`lazy-free`的机制，用于异步释放大key的内存，降低对Redis性能的影响。即使这样，我们也不建议使用大key，大key在集群的迁移过程中，也会影响到迁移的性能，这个后面在介绍集群相关的文章时，会再详细介绍到。

### 集中过期

有时你会发现，平时在使用Redis时没有延时比较大的情况，但在某个时间点突然出现一波延时，而且**报慢的时间点很有规律，例如某个整点，或者间隔多久就会发生一次**。

如果出现这种情况，就需要考虑是否存在大量key集中过期的情况。

如果有大量的key在某个固定时间点集中过期，在这个时间点访问Redis时，就有可能导致延迟增加。

Redis的过期策略采用主动过期+懒惰过期两种策略：

- 主动过期：Redis内部维护一个定时任务，默认每隔100毫秒会从过期字典中随机取出20个key，删除过期的key，如果过期key的比例超过了25%，则继续获取20个key，删除过期的key，循环往复，直到过期key的比例下降到25%或者这次任务的执行耗时超过了25毫秒，才会退出循环
- 懒惰过期：只有当访问某个key时，才判断这个key是否已过期，如果已经过期，则从实例中删除

注意，**Redis的主动过期的定时任务，也是在Redis主线程中执行的**，也就是说如果在执行主动过期的过程中，出现了需要大量删除过期key的情况，那么在业务访问时，必须等这个过期任务执行结束，才可以处理业务请求。此时就会出现，业务访问延时增大的问题，最大延迟为25毫秒。

而且这个访问延迟的情况，**不会记录在慢日志里**。慢日志中**只记录真正执行某个命令的耗时**，Redis主动过期策略执行在操作命令之前，如果操作命令耗时达不到慢日志阈值，它是不会计算在慢日志统计中的，但我们的业务却感到了延迟增大。

此时你需要检查你的业务，是否真的存在集中过期的代码，一般集中过期使用的命令是`expireat`或`pexpireat`命令，在代码中搜索这个关键字就可以了。

如果你的业务确实需要集中过期掉某些key，又不想导致Redis发生抖动，有什么优化方案？

解决方案是，**在集中过期时增加一个随机时间，把这些需要过期的key的时间打散即可。**

伪代码可以这么写：

```
# 在过期时间点之后的5分钟内随机过期掉
redis.expireat(key, expire_time + random(300))
```

这样Redis在处理过期时，不会因为集中删除key导致压力过大，阻塞主线程。

另外，除了业务使用需要注意此问题之外，还可以通过运维手段来及时发现这种情况。

做法是我们需要把Redis的各项运行数据监控起来，执行`info`可以拿到所有的运行数据，在这里我们需要重点关注`expired_keys`这一项，它代表整个实例到目前为止，累计删除过期key的数量。

我们需要对这个指标监控，当在**很短时间内这个指标出现突增**时，需要及时报警出来，然后与业务报慢的时间点对比分析，确认时间是否一致，如果一致，则可以认为确实是因为这个原因导致的延迟增大。

### 实例内存达到上限

有时我们把Redis当做纯缓存使用，就会给实例设置一个内存上限`maxmemory`，然后开启LRU淘汰策略。

当实例的内存达到了`maxmemory`后，你会发现之后的每次写入新的数据，有可能变慢了。

导致变慢的原因是，当Redis内存达到`maxmemory`后，每次写入新的数据之前，必须先踢出一部分数据，让内存维持在`maxmemory`之下。

这个踢出旧数据的逻辑也是需要消耗时间的，而具体耗时的长短，要取决于配置的淘汰策略：

- allkeys-lru：不管key是否设置了过期，淘汰最近最少访问的key
- volatile-lru：只淘汰最近最少访问并设置过期的key
- allkeys-random：不管key是否设置了过期，随机淘汰
- volatile-random：只随机淘汰有设置过期的key
- allkeys-ttl：不管key是否设置了过期，淘汰即将过期的key
- noeviction：不淘汰任何key，满容后再写入直接报错
- allkeys-lfu：不管key是否设置了过期，淘汰访问频率最低的key（4.0+支持）
- volatile-lfu：只淘汰访问频率最低的过期key（4.0+支持）

具体使用哪种策略，需要根据业务场景来决定。

我们最常使用的一般是`allkeys-lru`或`volatile-lru`策略，它们的处理逻辑是，每次从实例中随机取出一批key（可配置），然后淘汰一个最少访问的key，之后把剩下的key暂存到一个池子中，继续随机取出一批key，并与之前池子中的key比较，再淘汰一个最少访问的key。以此循环，直到内存降到`maxmemory`之下。

如果使用的是`allkeys-random`或`volatile-random`策略，那么就会快很多，因为是随机淘汰，那么就少了比较key访问频率时间的消耗了，随机拿出一批key后直接淘汰即可，因此这个策略要比上面的LRU策略执行快一些。

但以上这些逻辑都是在访问Redis时，**真正命令执行之前执行的**，也就是它会影响我们访问Redis时执行的命令。

另外，如果此时Redis实例中有存储大key，那么**在淘汰大key释放内存时，这个耗时会更加久，延迟更大**，这需要我们格外注意。

如果你的业务访问量非常大，并且必须设置`maxmemory`限制实例的内存上限，同时面临淘汰key导致延迟增大的的情况，要想缓解这种情况，除了上面说的避免存储大key、使用随机淘汰策略之外，也可以考虑**拆分实例**的方法来缓解，拆分实例可以把一个实例淘汰key的压力**分摊到多个实例**上，可以在一定程度降低延迟。

### fork耗时严重

如果你的Redis开启了自动生成RDB和AOF重写功能，那么有可能在后台生成RDB和AOF重写时导致Redis的访问延迟增大，而等这些任务执行完毕后，延迟情况消失。

遇到这种情况，一般就是执行生成RDB和AOF重写任务导致的。

生成RDB和AOF都需要父进程`fork`出一个子进程进行数据的持久化，**在`fork`执行过程中，父进程需要拷贝内存页表给子进程，如果整个实例内存占用很大，那么需要拷贝的内存页表会比较耗时，此过程会消耗大量的CPU资源，在完成`fork`之前，整个实例会被阻塞住，无法处理任何请求，如果此时CPU资源紧张，那么`fork`的时间会更长，甚至达到秒级。这会严重影响Redis的性能**。

我们可以执行`info`命令，查看最后一次`fork`执行的耗时`latest_fork_usec`，单位微妙。这个时间就是整个实例阻塞无法处理请求的时间。

除了因为备份的原因生成RDB之外，**在主从节点第一次建立数据同步时**，主节点也会生成RDB文件给从节点进行一次全量同步，这时也会对Redis产生性能影响。

要想避免这种情况，我们需要规划好数据备份的周期，建议在**从节点上执行备份，而且最好放在低峰期执行**。如果对于丢失数据不敏感的业务，那么不建议开启AOF和AOF重写功能。

另外，`fork`的耗时也与系统有关，如果把Redis部署在虚拟机上，那么这个时间也会增大。所以使用Redis时建议部署在物理机上，降低`fork`的影响。

### 绑定CPU

很多时候，我们在部署服务时，为了提高性能，降低程序在使用多个CPU时上下文切换的性能损耗，一般会采用进程绑定CPU的操作。

但在使用Redis时，我们不建议这么干，原因如下。

**绑定CPU的Redis，在进行数据持久化时，`fork`出的子进程，子进程会继承父进程的CPU使用偏好，而此时子进程会消耗大量的CPU资源进行数据持久化，子进程会与主进程发生CPU争抢，这也会导致主进程的CPU资源不足访问延迟增大。**

所以在部署Redis进程时，如果需要开启RDB和AOF重写机制，一定不能进行CPU绑定操作！

### 开启AOF

上面提到了，当执行AOF文件重写时会因为`fork`执行耗时导致Redis延迟增大，除了这个之外，如果开启AOF机制，设置的策略不合理，也会导致性能问题。

开启AOF后，Redis会把写入的命令实时写入到文件中，但写入文件的过程是先写入内存，等内存中的数据超过一定阈值或达到一定时间后，内存中的内容才会被真正写入到磁盘中。

AOF为了保证文件写入磁盘的安全性，提供了3种刷盘机制：

- `appendfsync always`：每次写入都刷盘，对性能影响最大，占用磁盘IO比较高，数据安全性最高
- `appendfsync everysec`：1秒刷一次盘，对性能影响相对较小，节点宕机时最多丢失1秒的数据
- `appendfsync no`：按照操作系统的机制刷盘，对性能影响最小，数据安全性低，节点宕机丢失数据取决于操作系统刷盘机制

当使用第一种机制`appendfsync always`时，Redis每处理一次写命令，都会把这个命令写入磁盘，而且**这个操作是在主线程中执行的**。

内存中的的数据写入磁盘，这个会加重磁盘的IO负担，操作磁盘成本要比操作内存的代价大得多。如果写入量很大，那么每次更新都会写入磁盘，此时机器的磁盘IO就会非常高，拖慢Redis的性能，因此我们不建议使用这种机制。

与第一种机制对比，`appendfsync everysec`会每隔1秒刷盘，而`appendfsync no`取决于操作系统的刷盘时间，安全性不高。因此我们推荐使用`appendfsync everysec`这种方式，在最坏的情况下，只会丢失1秒的数据，但它能保持较好的访问性能。

当然，对于有些业务场景，对丢失数据并不敏感，也可以不开启AOF。

### 使用Swap

如果你发现Redis突然变得非常慢，**每次访问的耗时都达到了几百毫秒甚至秒级**，那此时就检查Redis是否使用到了Swap，这种情况下Redis基本上已经无法提供高性能的服务。

我们知道，操作系统提供了Swap机制，目的是为了当内存不足时，可以把一部分内存中的数据换到磁盘上，以达到对内存使用的缓冲。

但当内存中的数据被换到磁盘上后，访问这些数据就需要从磁盘中读取，这个速度要比内存慢太多！

**尤其是针对Redis这种高性能的内存数据库来说，如果Redis中的内存被换到磁盘上，对于Redis这种性能极其敏感的数据库，这个操作时间是无法接受的。**

我们需要检查机器的内存使用情况，确认是否确实是因为内存不足导致使用到了Swap。

如果确实使用到了Swap，要及时整理内存空间，释放出足够的内存供Redis使用，然后释放Redis的Swap，让Redis重新使用内存。

释放Redis的Swap过程通常要重启实例，为了避免重启实例对业务的影响，一般先进行主从切换，然后释放旧主节点的Swap，重新启动服务，待数据同步完成后，再切换回主节点即可。

可见，当Redis使用到Swap后，此时的Redis的高性能基本被废掉，所以我们需要提前预防这种情况。

**我们需要对Redis机器的内存和Swap使用情况进行监控，在内存不足和使用到Swap时及时报警出来，及时进行相应的处理。**

### 网卡负载过高

如果以上产生性能问题的场景，你都规避掉了，而且Redis也稳定运行了很长时间，但在某个时间点之后开始，访问Redis开始变慢了，而且一直持续到现在，这种情况是什么原因导致的？

之前我们就遇到这种问题，**特点就是从某个时间点之后就开始变慢，并且一直持续**。这时你需要检查一下机器的网卡流量，是否存在网卡流量被跑满的情况。

**网卡负载过高，在网络层和TCP层就会出现数据发送延迟、数据丢包等情况。Redis的高性能除了内存之外，就在于网络IO，请求量突增会导致网卡负载变高。**

如果出现这种情况，你需要排查这个机器上的哪个Redis实例的流量过大占满了网络带宽，然后确认流量突增是否属于业务正常情况，如果属于那就需要及时扩容或迁移实例，避免这个机器的其他实例受到影响。

运维层面，我们需要对机器的各项指标增加监控，包括网络流量，在达到阈值时提前报警，及时与业务确认并扩容。

### 总结

以上我们总结了Redis中常见的可能导致延迟增大甚至阻塞的场景，这其中既涉及到了业务的使用问题，也涉及到Redis的运维问题。

可见，要想保证Redis高性能的运行，其中涉及到CPU、内存、网络，甚至磁盘的方方面面，其中还包括操作系统的相关特性的使用。

作为开发人员，我们需要了解Redis的运行机制，例如各个命令的执行时间复杂度、数据过期策略、数据淘汰策略等，使用合理的命令，并结合业务场景进行优化。

作为DBA运维人员，需要了解数据持久化、操作系统`fork`原理、Swap机制等，并对Redis的容量进行合理规划，预留足够的机器资源，对机器做好完善的监控，才能保证Redis的稳定运行。



## 你遇到 Redis 线上连接超时一般如何处理？

一封报警邮件，大量服务节点 redis 响应超时。

又来，好烦。

redis 响应变慢，查看日志，发现大量 TimeoutException。

大量TimeoutException，说明当前redis服务节点上已经堆积了大量的连接查询，超出redis服务能力，再次尝试连接的客户端，redis 服务节点直接拒绝，抛出错误。

**那到底是什么导致了这种情况的发生呢？**

总结起来，我们可以从以下几方面进行关注：

### 一、redis 服务节点受到外部关联影响

redis服务所在服务器，物理机的资源竞争及网络状况等。同一台服务器上的服务必然面对着服务资源的竞争，CPU，内存，固存等。

**1、CPU资源竞争**

redis属于CPU密集型服务，对CPU资源依赖尤为紧密，当所在服务器存在其它CPU密集型应用时，必然会影响redis的服务能力，尤其是在其它服务对CPU资源消耗不稳定的情况下。

因此，在实际规划redis这种基础性数据服务时应该注意一下几点：

- 一般不要和其它类型的服务进行混部。
- 同类型的redis服务，也应该针对所服务的不同上层应用进行资源隔离。

说到CPU关联性，可能有人会问是否应该对redis服务进行CPU绑定，以降低由CPU上下文切换带来的性能消耗及关联影响？

简单来说，是可以的，这种优化可以针对任何CPU亲和性要求比较高的服务，但是在此处，有一点我们也应该特别注意：我们在 关于redis内存分析，内存优化 中介绍内存时，曾经提到过子进程内存消耗，也就是redis持久化时会fork出子进程进行AOF/RDB持久化任务。

对于开启了持久化配置的redis服务（一般情况下都会开启），假如我们做了CPU亲和性处理，那么redis fork出的子进程则会和父进程共享同一个CPU资源，我们知道，redis持久化进程是一个非常耗资源的过程，这种自竞争必然会引发redis服务的极大不稳定。

**2、内存不在内存了**

[关于redis内存分析，内存优化 ](http://mp.weixin.qq.com/s?__biz=MzIyNDU2ODA4OQ==&mid=2247484460&idx=1&sn=fbe1377d2e51451311aa910c92de022a&chksm=e80db25adf7a3b4c9d3b38c5c3c73e6ce97dbbcf8c8249acddc452352bf771f28a5ad82c02b1&scene=21#wechat_redirect)开篇就讲过，redis最重要的东西，内存。

内存稳定性是redis提供稳定，低延迟服务的最基本的要求。

然而，我们也知道操作系统有一个 swap 的东西，也就将内存交换到硬盘。假如发生了redis内存被交换到硬盘的情景发生，那么必然，redis服务能力会骤然下降。

swap发现及避免：

**2.1 info memory：**

[关于redis内存分析，内存优化](http://mp.weixin.qq.com/s?__biz=MzIyNDU2ODA4OQ==&mid=2247484460&idx=1&sn=fbe1377d2e51451311aa910c92de022a&chksm=e80db25adf7a3b4c9d3b38c5c3c73e6ce97dbbcf8c8249acddc452352bf771f28a5ad82c02b1&scene=21#wechat_redirect) 中我们也讲过，swap这种情景，此时，查看redis的内存信息，可以观察到碎片率会小于1。这也可以作为监控redis服务稳定性的一个指标。

**2.2 通过redis进程查看**

首先通过 info server 获取进程id：

![image-20210306140348329](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140348329.png)

查看 redis 进程 swap 情况：`cat /proc/1686/smaps`

![image-20210306140414150](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140414150.png)

确定交换量都为0KB或者4KB。

**2.3 redis服务maxmemory配置**

关于redis内存分析，内存优化 中我们提到过，对redis服务必要的内存上限配置，这是内存隔离的一种必要。需要确定的是所有redis实例的分配内存总额小于总的可用物理内存。

**2.4 系统优化：**

另外，在最初的基础服务操作系统安装部署时，也需要做一些必要的前置优化，如关闭swap或配置系统尽量避免使用。

**3、网络问题**

网络问题，是一个普遍的影响因素。

**3.1 网络资源耗尽**

简单来说，就是带宽不够了，整个属于基础资源架构的问题了，对网络资源的预估不足，跨机房，异地部署等都会成为诱因。

**3.2 连接数用完了**

一个客户端连接对应着一个TCP连接，一个TCP连接在LINUX系统内对应着一个文件句柄，系统级别连接句柄用完了，也就无法再进行连接了。（更多面试题，欢迎关注公众号 Java面试题精选）

查看当前系统限制：`ulimit -n`

设置：`ulimit -n {num}`

**3.3 端口TCP backlog队列满了**

linux系统对于每个端口使用backlog保存每一个TCP连接。

redis配置：tcp_backlog 默认511

![image-20210306140450683](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140450683.png)

高并发情境下，可以适当调整此配置，但需要注意的是，同时要调整系统相关设置。

系统修改命令：`echo {num}>/proc/sys/net/core/somaxconn`

查看因为队列溢出导致的连接绝句：`netstat -s | grep overflowed`

![image-20210306140510768](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140510768.png)

**3.4 网络延迟**

网络质量问题，可以使用 redis-cli 进行网络状况的测试：

延迟测试：`redis-cli -h {host} -p {port} --latency`

![image-20210306140539851](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140539851.png)

采样延迟测试：`redis-cli -h {host} -p {port} --latency-history` 默认15s一次

![image-20210306140558198](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140558198.png)

图形线上测试结果：`redis-cli -h {host} -p {port} --latency-dist`

![image-20210306140618127](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140618127.png)

**3.5 网卡软中断**

单个网卡队列只能使用单个CPU资源问题。

### 二、redis 服务使用问题

**1、慢查询**

如果你的查询总是慢查询，那么必然你的使用存在不合理。

**1.1 你的key规划是否合理**

太长或太短都是不建议的，key需要设置的简短而有意义。

**1.2 值类型选择是否合理。**

hash还是string，set还是zset，避免大对象存储。

线上可以通过scan命令进行大对象发现治理。

**1.3 是否能够批查询**

get 还是 mget；是否应该使用pipeline。

**1.4 禁止线上大数据量操作**

**2、redis 服务运行状况**

查看redis服务运行状况：`redis-cli -h {host} -p {port} --stat`

![image-20210306140707752](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140707752.png)

keys：当前key总数；mem：内存使用；clients：当前连接client数；blocked：阻塞数；requests：累计请求数；connections：累计连接数

**3、持久化操作影响**

**3.1 fork子进程影响**

redis 进行持久化操作需要fork出子进程。fork子进程本身如果时间过长，则会产生一定的影响。

查看命令最近一次fork耗时：`info stats`

![image-20210306140731192](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/redis-demo/image-20210306140731192.png)

单位微妙，确保不要超过1s。

**3.2 AOF刷盘阻塞**

AOF持久化开启，后台每秒进行AOF文件刷盘操作，系统fsync操作将AOF文件同步到硬盘，如果主线程发现距离上一次成功fsync超过2s，则会阻塞后台线程等待fsync完成以保障数据安全性。

**3.3 THP问题**

关于redis内存分析，内存优化 中我们讲过透明大页问题，linux系统的写时复制机制会使得每次写操作引起的页复制由4KB提升至2M从而导致写慢查询。如果慢查询堆积必然导致后续连接问题。

























## 如何用Redis解决海量数据的日活、月活问题？



## 如何用Redis解决高并发下黑名单、白名单问题？



## 在大数据环境中，Redis能解决什么问题？



## 在高并发下，基于并发安全，如何实现高质量的分布式锁？



## 如何进行Redis的性能优化？如何进行Redis集群方案的选择？



## Redis的数据一致性如何处理？



## 阐述下Redis6.*的新特性













