[toc]

# Java 网络编程基础

## 1.OSI七层模型和TCP/IP五层模型

### 1.1.OSI参考模型

**1.1.1.OSI的来源**

OSI（Open System Interconnect），即开放式系统互联。 一般都叫OSI参考模型，是ISO（国际标准化组织）组织在1985年研究的网络互连模型。

ISO为了更好的使网络应用更为普及，推出了OSI参考模型。其含义就是推荐所有公司使用这个规范来控制网络。这样所有公司都有相同的规范，就能互联了。

**1.1.2.OSI七层模型的划分**

OSI定义了网络互连的七层框架（物理层、数据链路层、网络层、传输层、会话层、表示层、应用层），即ISO开放互连系统参考模型。

每一层实现各自的功能和协议，并完成与相邻层的接口通信。OSI的服务定义详细说明了各层所提供的服务。某一层的服务就是该层及其下各层的一种能力，它通过接口提供给更高一层。各层所提供的服务与这些服务是怎么实现的无关。

![17849411-6cad6d1b0aafdd22](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321221042.webp)

**1.1.3.各层功能定义**

这里我们只对OSI各层进行功能上的大概阐述，不详细深究，因为每一层实际都是一个复杂的层。后面我也会根据个人方向展开部分层的深入学习。这里我们就大概了解一下。我们从最顶层——应用层 开始介绍。整个过程以公司A和公司B的一次商业报价单发送为例子进行讲解。

**<1>  应用层**

OSI参考模型中最靠近用户的一层，是为计算机用户提供应用接口，也为用户直接提供各种网络服务。我们常见应用层的网络服务协议有：HTTP，HTTPS，FTP，POP3、SMTP等。

**实际公司A的老板就是我们所述的用户，而他要发送的商业报价单，就是应用层提供的一种网络服务，当然，老板也可以选择其他服务，比如说，发一份商业合同，发一份询价单，等等。**

**<2>  表示层**

表示层提供各种用于应用层数据的编码和转换功能,确保一个系统的应用层发送的数据能被另一个系统的应用层识别。如果必要，该层可提供一种标准表示形式，用于将计算机内部的多种数据格式转换成通信中采用的标准表示形式。数据压缩和加密也是表示层可提供的转换功能之一。

**由于公司A和公司B是不同国家的公司，他们之间的商定统一用英语作为交流的语言，所以此时表示层（公司的文秘），就是将应用层的传递信息转翻译成英语。同时为了防止别的公司看到，公司A的人也会对这份报价单做一些加密的处理。这就是表示的作用，将应用层的数据转换翻译等。**

**<3>  会话层**

会话层就是负责建立、管理和终止表示层实体之间的通信会话。该层的通信由不同设备中的应用程序之间的服务请求和响应组成。   

**会话层的同事拿到表示层的同事转换后资料，（会话层的同事类似公司的外联部），会话层的同事那里可能会掌握本公司与其他好多公司的联系方式，这里公司就是实际传递过程中的实体。他们要管理本公司与外界好多公司的联系会话。当接收到表示层的数据后，会话层将会建立并记录本次会话，他首先要找到公司B的地址信息，然后将整份资料放进信封，并写上地址和联系方式。准备将资料寄出。等到确定公司B接收到此份报价单后，此次会话就算结束了，外联部的同事就会终止此次会话。**

**<4>  传输层**

传输层建立了主机端到端的链接，传输层的作用是为上层协议提供端到端的可靠和透明的数据传输服务，包括处理差错控制和流量控制等问题。该层向高层屏蔽了下层数据通信的细节，使高层用户看到的只是在两个传输实体间的一条主机到主机的、可由用户控制和设定的、可靠的数据通路。我们通常说的，TCP UDP就是在这一层。端口号既是这里的“端”。

**传输层就相当于公司中的负责快递邮件收发的人，公司自己的投递员，他们负责将上一层的要寄出的资料投递到快递公司或邮局。**

**<5>  网络层**

本层通过IP寻址来建立两个节点之间的连接，为源端的运输层送来的分组，选择合适的路由和交换节点，正确无误地按照地址传送给目的端的运输层。就是通常说的IP层。这一层就是我们经常说的IP协议层。IP协议是Internet的基础。

**网络层就相当于快递公司庞大的快递网络，全国不同的集散中心，比如说，从深圳发往北京的顺丰快递（陆运为例啊，空运好像直接就飞到北京了），首先要到顺丰的深圳集散中心，从深圳集散中心再送到武汉集散中心，从武汉集散中心再寄到北京顺义集散中心。这个每个集散中心，就相当于网络中的一个IP节点。**

**<6>  数据链路层** 

将比特组合成字节,再将字节组合成帧,使用链路层地址 (以太网使用MAC地址)来访问介质,并进行差错检测。

数据链路层又分为2个子层：逻辑链路控制子层（LLC）和媒体访问控制子层（MAC）。

MAC子层处理CSMA/CD算法、数据出错校验、成帧等；LLC子层定义了一些字段使上次协议能共享数据链路层。 在实际使用中，LLC子层并非必需的。

这个没找到合适的例子

**<7> 物理层**  

实际最终信号的传输是通过物理层实现的。通过物理介质传输比特流。规定了电平、速度和电缆针脚。常用设备有（各种物理设备）集线器、中继器、调制解调器、网线、双绞线、同轴电缆。这些都是物理层的传输介质。

**快递寄送过程中的交通工具，就相当于我们的物理层，例如汽车，火车，飞机，船。**

**1.1.4.通信特点：对等通信**

对等通信，为了使数据分组从源传送到目的地，源端OSI模型的每一层都必须与目的端的对等层进行通信，这种通信方式称为对等层通信。在每一层通信过程中，使用本层自己协议进行通信。

![17849411-637c731976fd3568](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321221255.webp)

### 1.2.TCP/IP五层模型

 TCP/IP五层协议和OSI的七层协议对应关系如下。

![17849411-fa0c0490a6e0957a](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321221308.webp)

在每一层都工作着不同的设备，比如我们常用的交换机就工作在数据链路层的，一般的路由器是工作在网络层的。

![17849411-9d0db57e4fd6afcd](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321221322.webp)

在每一层实现的协议也各不同，即每一层的服务也不同.下图列出了每层主要的协议。其中每层中具体的协议，我会在后面的逐一学习。

![17849411-217ab26f0b92f040](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321221327.webp)



## 2.网络协议

### 2.1.IP协议

#### 2.1.1.概念

IP协议是TCP/IP协议簇中的核心协议，也是TCP/IP的载体。所有的TCP，UDP，ICMP及IGMP数据都以IP数据报格式传输。 

IP提供不可靠的，无连接的数据传送服务。 

- 不可靠指它不能保证IP数据报能成功到达目的地。 

  IP仅提供最好的传输服务。当发生某种错误时，如某个路由器暂时用完了缓冲区，IP有一个简单的错误处理算法：丢弃该数据报，然后发送ICMP消息给信源。任何要求的可靠性必须由上层来提供。 

- 无连接指IP并不维护任何关于后续数据报的状态信息。 

  每个数据报的处理是相互独立的。IP数据报可以不按发送顺序接收。如果一信源向相同的信宿发送两个连续的数据报（先是A，然后是B）每个数据报都是独立的进行路由选择，可能选择不同的路线，因此B可能在A到达之前先到达。

#### 2.1.2.简介

![20180527095330265](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321221703.png)

上图中： 

- 主机：是配有IP地址, 但是不进行路由控制的设备； 

- 路由器: 即配有IP地址, 又能进行路由控制； 

- 节点: 主机和路由器的统称；

#### 2.1.3.协议头格式

![20180527100255831](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321221758.png)

解析：

| 字段                         | 解释                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| 4位版本号(version)           | 指定IP协议的版本, 对于IPv4来说，就是4                        |
| 4位头部长度(header length)   | IP头部的长度是多少个32bit, 也就是 length * 4 的字节数. 4bit表示最大的数字是15, 因此IP头部最大长度是60字节 |
| 8位服务类型(Type Of Service) | 3位优先权字段(已经弃用), 4位TOS字段, 和1位保留字段(必须置0). 4位TOS（最小延时, 最大吞吐量, 最高可靠性, 最小成本),只能选其一. ssh/telnet这样的应用程序, 最小延时比较重要; 对于ftp这样的程序, 最大吞吐量比较重要 |
|16位总长度(total length)	|IP数据报整体占多少个字节|
|16位标识(id)	|唯一的标识主机发送的报文. 如果IP报文在数据链路层被分片了, 那么每一个片里面的这个id是相同的|
|3位标志字段	|第一位保留，第二位置为1表示禁止分片, 这时候如果报文长度超MTU, IP模块就会丢弃报文. 第三位表示”更多分片”, 如果分片了的话, 最后一个分片置为1, 其他是0|
|13位分片偏移(framegament offset)	|是分片相对于原始IP报文开始处的偏移. 其实就是在表示当前分片在原报文中处在哪个位置|
|8位生存时间(Time To Live, TTL)|	数据报到达目的地的最大报文跳数|
|8位协议|	表示上层协议的类型|
|16位头部校验和|	使用CRC进行校验, 来鉴别头部是否损坏|
|32位源地址和32位目标地址|	表示发送端和接收端|
|选项字段	|不定长, 最多40字节|

#### 2.1.4.网段划分

**为什么要进行网段划分呢？** 

我们寻找某台主机时，在同一个网段的主机网络号都是相同的，我们可以根据网络号确定一个区域，再通过主机号寻找目的主机。因此,我们需要知道：

- IP地址分为两个部分, 网络号和主机号

- 网络号: 保证相互连接的两个网段具有不同的标识

- 主机号: 同一网段内, 主机之间具有相同的网络号, 但是必须有不同的主机号；

- 不同的子网其实是把网络号相同的主机放到一起.

- 如果在子网中新增一台主机, 则这台主机的网络号和这个子网的网络号一致, 但是主机号必须不能和子网中的其他主机重复。

- 主机号为1的一般都为路由器接口。

所以，通过合理设置网络号的主机号，就可以保证在相互连接的网络中，每台主机的IP地址都不相同。 

但是，手动管理子网内的IP，是一个相当麻烦的事情。 

因此出现了一种叫做DHCP的技术，能够自动给子网内新增主机节点分配IP地址，避免了手动管理IP的不方便。且一般的路由器都带有DHCP功能. 因此路由器也可以看做一个DHCP服务器。

#### 2.1.5.IP地址划分类

所有IP 地址可以分为五类，如下： 

![20180527105326629](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321222227.png)

| 分类 | 地址范围                   |
| ---- | -------------------------- |
| A类  | 0.0.0.0到127.255.255.255   |
| B类  | 128.0.0.0到191.255.255.255 |
| C类  | 192.0.0.0到223.255.255.255 |
| D类  | 224.0.0.0到239.255.255.255 |
| E类  | 240.0.0.0到247.255.255.255 |

但是随着Internet的飞速发展，这种划分方案的局限性很快显现出来，大多数组织都申请B类网络地址, 导致B类地址很快就分配完了，而A类却浪费了大量地址。 

针对这种情况提出了新的划分方案, 称为CIDR(Classless Interdomain Routing)

#### 2.1.6.子网划分

我们都知道，IP地址是以网络号和主机号标识网络上的主机的，只有在同一网络号下的主机才可以“直接”互通，不同网络号的主机要通过网关互通。

为了使同一个网络下有多个子网，就产生了子网掩码。

了解一下这个新概念： 

**子网掩码**

- 区分网络号和主机号

- 是一个32位的正整数. 通常用一串 “0” 来结尾

- 将IP地址和子网掩码进行 “按位与” 操作, 得到的结果就是网络号

- 网络号和主机号的划分与这个IP地址是A类、B类还是C类无关

**那么如何确定子网掩码呢?**

将一个网络划分为多个子网，网络号就要占用原来的主机位。 

例如： 

C类地址，21位标识网络号，8位标识主机号，要将其划分为4个子网，则需占用2位原来的主机标识位。 

此时，网络号由之前的21位变为23位，子网掩码为：255.255.255.224 

如下图： 

![20180527215500464](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321222404.png)

#### 2.1.7.特殊的IP地址

将IP地址中的主机地址全部设为0, 就是网络号, 代表这个局域网

将IP地址中的主机地址全部设为1, 就成为了广播地址, 用于给同一个链路中相互连接的所有主机发送数据包

`127.*` 的IP地址用于本机环回(loop back)测试,通常是127.0.0.1

**那么IP地址的数量没有限制吗？** 

我们知道，IP（IPV4）地址是一个四字节32位的正整数，那么一共只有2的32次方个IP地址，大概是43亿左右，而 TCP/IP协议规定, 每个主机都需要有一个IP地址，那也就是说网络中最多只可以接入43亿主机吗？

实际上，由于一些特殊的IP地址的存在，数量就不足43亿了。另外，IP地址并非是按照主机台数配置的，而是每个网卡都需要配置一个或多个IP地址。

上文讲的子网划分，在一定程度上缓解了IP地址不够用的问题，提高了利用率，减少了浪费，但IP地址的绝对上限并没有增加，仍然不够用，会有三种方式来解决IP地址不够用的问题： 
1. 动态分配IP地址: 只给接入网络的设备分配IP地址. 因此同一个MAC地址的设备, 每次接入互联网中得到的IP地址不一定是相同的 
2. NAT技术 
3. IPv6: IPv6用16字节128位来表示一个IP地址; 但是目前IPv6还没有普及。 

**注意：IPv6并不是IPv4的简单升级版. 这是互不相干的两个协议**

**私有IP地址和公网IP地址**

1. 私有IP地址 
   
如果一个组织内部组建局域网,IP地址只用于局域网内的通信,而不直接连到Internet上，对与组建局域网的私有IP地址有如下规则： 
   
- 前8位是网络号,共16,777,216个地址 
   
   - 172.16. 到 172.31.，前12位是网络号,共1,048,576个地址 
- `192.168.*`,前16位是网络号,共65,536个地址 
   
2. 公网IP 

   如1中，包含在范围中的, 都成为私有IP, 其余的就称为全局IP(或公网IP)。 

   观察下图：

   ![20180527220844348](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321222632.png)

   可以知道： 

   - （1）一个路由器可以配置两个IP地址, 一个是WAN口IP, 一个是LAN口IP(子网IP). 
   - （2）路由器LAN口连接的主机，都从属于当前这个路由器的子网中. 
   - （3）不同的路由器, 子网IP其实都是一样的(通常都是192.168.1.1) 
   - （4）子网内的主机IP地址不能重复，但是子网之间的IP地址可以重复，所以，不同子网中的两个主机不可以进行访问。 
   - （5）子网中的主机需要和外网进行通信时，路由器将IP首部中的IP地址进行替换，替换成WAN口IP，逐级替换，最终数据包中的IP地址成为一个公网IP，这种技术被称为NAT（Network Address Translation，网络地址转换)。

#### 2.1.8.路由

路由，简单来说，就是在复杂的网络结构中, 一跳一跳找出一条通往终点的路线。

所谓 “一跳” 就是数据链路层中的一个区间. 具体在以太网中指从源MAC地址到目的MAC地址之间的帧传输区间。

IP数据包的传输过程 

（1）当IP数据包, 到达路由器时, 路由器会先查看目的IP; 

（2）路由器决定这个数据包是能直接发送给目标主机, 还是需要发送给下一个路由器; 

（3）依次反复, 一直到达目标IP地址; 

那么如何知道当前这个数据包该发送到哪里呢? 

这就依靠每个节点内部维护一个路由表，如果目的IP命中了路由表，就直接转发。 

我们可以用命令route 查看路由表： 

![20180527222601737](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321222811.png)

观察上图： 

我的主机有一个网络接口,连到192.168.1.0/24网络； 

注意：路由表中的最后一行,主要由下一跳地址和发送接口两部分组成,当目的地址与路由表中其它行都不匹配时,就按缺省路由条目规定的接口发送到下一跳地址 

分析一下上图各字段的含义：

| 字段        | 含义                                                         |
| ----------- | ------------------------------------------------------------ |
| Destination | 目的网络地址                                                 |
| Genmask     | ⼦⽹掩码                                                     |
| Gateway     | 下⼀一跳地址                                                 |
| Iface       | 发送接⼝                                                     |
| Flags       | U标志表示此条目有效(可以禁⽤某些条⽬)，G标志表示此条目的下⼀跳地址是某路由器的地址,没有G标志表示目的网络地址是与本机接⼝直接相连的网络,不必经路由器转发 |

路由转发过程： 

（1）拿到将要发送数据包的目的地址 

（2）先和第一行的子网掩码进行与运算，与第一行的目的网络地址不符，再和下一行的子网掩码做与运算，若匹配，因为是直接相连的网络，直接发到目的主机,不需要经路由器转发 

（3）若直到最后一行之前，发现都不匹配，按缺省路由条目，从eth0接口将该IP地址发给路由器，该路由器的路由表决定下一跳的地址。



### 2.2.TCP协议

#### 2.2.1.概述

**1. tcp连接的特点**

- 提供面向连接的，可靠的字节流服务
- 为上层应用层提供服务，不关心具体传输的内容是什么，也不知道是二进制流，还是ascii字符。

**2. tcp的可靠性如何保证**

- 分块传送：数据被分割成**最合适的**数据块（UDP的数据报长度不变）
- 等待确认：通过定时器等待接收端发送确认请求，收不到确认则重发
- 确认回复：收到确认后发送确认回复(不是立即发送，通常推迟几分之一秒)
- 数据校验：保持首部和数据的校验和，检测数据传输过程有无变化
- 乱序排序：接收端能重排序数据，以正确的顺序交给应用端
- 重复丢弃：接收端能丢弃重复的数据包
- 流量缓冲：两端有固定大小的缓冲区（滑动窗口），防止速度不匹配丢数据

**3. tcp的首部格式**

**3.1 宏观位置**

![1660a9b6dee9caf5](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223442.jpg)

- 从应用层->传输层->网络层->链路层，每经过一次都会在报文中增加相应的首部。
- TCP数据被封装在IP数据报中

**3.2 首部格式**

![1660aa15acdcc530](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223505.jpg)

- tcp首部数据通常包含20个字节（不包括任选字段）

- 第1-2两个字节：源端口号

- 第3-4两个字节：目的端口号

  > 源端口号+ip首部中的源ip地址+目的端口号+ip首部中的目的ip地址，唯一的确定了一个tcp连接。对应编码级别的socket。

- 第5-8四个字节：32位序号。tcp提供全双工服务，两端都有各自的序号。

  编号：解决网络包乱序的问题

  > 序号如何生成：不能是固定写死的，否则断网重连时序号重复使用会乱套。tcp基于时钟生成一个序号，每4微秒加一，到2^32-1时又从0开始

- 第9-12四个字节：32位确认序列号。上次成功收到数据字节序号加1，ack为1才有效。**确认号：解决丢包的问题**

- 第13位字节：首部长度。因为任选字段长度可变

- 后面6bite：保留

- 随后6bite：标识位。**控制各种状态**

- 第15-16两个字节：窗口大小。接收端期望接收的字节数。**解决流量控制的问题**

- 第17-18两个字节：校验和。由发送端计算和存储，由接收端校验。**解决数据正确性问题**

- 第19-20两个字节：紧急指针

**3.3 标识位说明**

- URG：为1时，表示紧急指针有效
- ACK：确认标识，连接建立成功后，总为1。为1时确认号有效
- PSH：接收方应尽快把这个报文交给应用层
- RST：复位标识，重建连接
- SYN：建立新连接时，该位为0
- FIN：关闭连接标识

**3.4 tcp选项格式**

![1661640d08bd9f5d](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223531.jpg)

- 每个选项开始是1字节kind字段，说明选项的类型
- kind为0和1的选项，只占一个字节
- 其他kind后有一字节len，表示该选项总长度（包括kind和len）
- kind为11，12，13表示tcp事务

**3.5 MSS 最长报文大小**

- 最常见的可选字段
- MSS只能出现在SYN时传过来（第一次握手和第二次握手时）
- 指明本端能接收的最大长度的报文段
- 建立连接时，双方都要发送MSS
- 如果不发送，默认为536字节

#### 2.2.2.连接的建立与释放

**2.2.2.1. 连接建立的“三次握手”**

**2.2.2.1.1 三次握手流程**

![1660af5dec5b3e88](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223617.jpg)

- 客户端发送SYN，表明要向服务器建立连接。同时带上序列号ISN
- 服务器返回ACK（序号为客户端序列号+1）作为确认。同时发送SYN作为应答（SYN的序列号为服务端唯一的序号）
- 客户端发送ACK确认收到回复（序列号为服务端序列号+1）

**2.2.2.1.2 为什么是三次握手**

- tcp连接是全双工的，数据在两个方向上能同时传递。
- 所以要**确保双方，同时能发数据和收数据**
- 第一次握手：证明了发送方能发数据
- 第二次握手：ack确保了接收方能收数据，syn确保了接收方能发数据
- 第三次握手：确保了发送方能收数据
- 实际上是四个维度的信息交换，不过中间两步合并为一次握手了。
- 四次握手浪费，两次握手不能保证“双方同时具备收发功能”

**2.2.2.2. 连接关闭的“四次挥手”**

**2.2.2.2.1 为什么是四次挥手**

- 因为tcp连接是全双工的，数据在两个方向上能同时传递。
- 同时tcp支持半关闭（发送一方结束发送还能接收数据的功能）。
- 因此每个方向都要单独关闭，且收到关系通知需要发送确认回复

**2.2.2.2.2 为什么要支持半关闭**

- 客户端需要通知服务端，它的数据已经传输完毕
- 同时仍要接收来自服务端的数据
- 使用半关闭的单连接效率要比使用两个tcp连接更好

**2.2.2.2.3 四次握手流程**

![1660b064e8802dba](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223659.jpg)

- 主动关闭的一方发送FIN，表示要单方面关闭数据的传输
- 服务端收到FIN后，发送一个ACK作为确认（序列号为收到的序列号+1）
- 等服务器数据传输完毕，也发送一个FIN标识，表示关闭这个方向的数据传输
- 客户端回复ACK以确认回复

**2.2.2.3. 连接和关闭对应的状态**

![1660b1eef5232c9f](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223722.jpg)

**2.2.2.3.1 状态说明**

- 服务端等待客户端连接时，处于Listen监听状态
- 客户端主动打开请求，发送SYN时处于SYN_SENT发送状态
- 客户端收到syn和ack，并回复ack时，处与Established状态等待发送报文
- 服务端收到ack确认后，也处于Established状态等待发送报文
- 客户端发送fin后，处于fin_wait_1状态
- 服务端收到fin并发送ack时，处于close_wait状态
- 客户端收到ack确认后，处于fin_wait_2状态
- 服务端发送fin后，处于last_ack状态
- 客户端收到fin后发送ack，处于time_wait状态
- 服务端收到ack后，处于closed状态

**2.2.2.3.2 time_wait状态**

- 也称为2MSL等待状态，MSL=Maximum Segment LifetIme，报文段最大生存时间，根据不同的tcp实现自行设定。常用值为30s，1min，2min。linux一般为30s。
- 主动关闭的一方发送最后一个ack所处的状态
- 这个状态必须维持2MSL等待时间

**2.2.2.3.2.1 为什么需要这么做？**

- 设想一个场景，最后这个ack丢失了，接收方没有收到
- 这时候接收方会重新发送fin给发送方
- 这个等待时间就是为了防止这种情况发生，让发送方重新发送ack
- 总结：预留足够的时间给接收端收ack。同时保证，这个连接不会和后续的连接乱套（有些路由器会缓存数据包）

**2.2.2.3.2.2 这么做的后果？**

- 在这2MSL等待时间内，该连接（socket，ip+port）将不能被使用
- 很多时候linux上报too many open files，说端口不够用了，就需要检查一些代码里面是不是创建大量的socket连接，而这些socket连接并不是关闭后就立马释放的
- 客户端连接服务器的时候，一般不指定客户端的端口。因为客户端关闭然后立马启动，按照理论来说是会提示端口被占用。同样的道理，主动关闭服务器，2MSL时间内立马启动是会报端口被占用的错误
- 多并发的短连接情况下，会出现大量的Time_wait状态。这两个参数可以解决问题，但是它违背了tcp协议，是有风险的。参数为：tcp_tw_reuse和tcp_tw_recycle
- 如果是服务端开发，可设置keep-alive，让客户端主动关闭连接解决这个问题

**2.2.2.4. 复位报文段**

一个报文段从源地址发往目的地址，只要出现错误，都会发出复位的报文段，首部字段的RST是用于“复位”的。这些错误包括以下情况

- 端口没有在监听
- 异常中止：通过发送RST而不是fin来中止连接

**2.2.2.5. 同时打开**

![16616378235fc20f](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223756.jpg)

- 两个应用程序同时执行主动打开，称为“同时打开“
- 这种情况极少发生
- 两端同时发送SYN，同时进入SYN_SENT状态
- 打开一条连接而不是两条
- 要进行四次报文交换过程，“四次握手”

**2.2.2.6. 同时关闭**

![166163c56e29b637](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223815.jpg)

- 双方同时执行主动关闭
- 进行四次报文交换
- 状态和正常关闭不一样

**2.2.2.7. 服务器对于并发请求的处理**

- 正等待连接的一端有一个固定长度的队列（长度叫做“积压值”，大多数情况长度为5）
- 该队列中的连接为：已经完成了三次握手，但还没有被应用层接收（应用层需要等待最后一个ack收到后才知道这个连接）
- 应用层接收请求的连接，将从该队列中移除
- 当新的请求到来时，先判断队列情况来决定是否接收这个连接
- 积压值的含义：tcp监听的端点已经被tcp接收，但是等待应用层接收的最大值。与系统允许的最大连接数，服务器接收的最大并发数无关

#### 2.2.3.数据的传输

**2.2.3.1. tcp传输的数据分类**

- 成块数据传输：量大，报文段常常满
- 交互数据传输：量小，报文段为微小分组，大量微小分组，在广域网传输会增加拥堵的出现
- tcp处理的数据包括两类，有不同的特点，需要不同的传输技术

**2.2.3.2. 交互数据的传输技术**

**2.2.3.2.1 经受时延的确认**

- 概念：tcp收到数据时，并不立马发送ack确认，而是稍后发送
- 目的：将ack与需要沿该方向发送的数据一起发送，以减少开销
- 特点：接收方不必确认每一个收到的分组，ACk是累计的，它表示接收方已经正确收到了一直到确认序号-1的所有字节
- 延时时间：绝大多数为200ms。不能超过500ms

**2.2.3.2.2 Nagle算法**

- 解决什么问题：微小分组导致在广域网出现的拥堵问题
- 核心：减少了通过广域网传输的小分组数目
- 原理：要求一个tcp连接上最多只能有一个未被确认的未完成的分组，该分组的确认到达之前，不能发送其他分组。tcp收集这些分组，确认到来之前以一个分组的形式发出去
- 优点：自适应。确认到达的快，数据发送越快。确认慢，发送更少的组。
- 使用注意：局域网很少使用该算法。且有些特殊场景需要禁用该算法

**2.2.3.3. 成块数据的传输**

- 主要使用滑动窗口协议

#### 2.2.4.滑动窗口协议

**2.2.4.1.  概述**

- 解决了什么问题：发送方和接收方速率不匹配时，保证可靠传输和包乱序的问题
- 机制：接收方根据目前缓冲区大小，通知发送方目前能接收的最大值。发送方根据接收方的处理能力来发送数据。通过这种协调机制，防止接收端处理不过来。
- 窗口大小：接收方发给发送端的这个值称为窗口大小

**2.2.4.2. tcp缓冲区的数据结构**

![166205f97ca0579f](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223915.jpg)

- 接收端：
  - LastByteRead: 缓冲区读取到的位置
  - NextByteExpected：收到的连续包的最后一个位置
  - LastByteRcvd：收到的包的最后一个位置
  - 中间空白区：数据没有到达
- 发送端：
  - LastByteAcked: 被接收端ack的位置，表示成功发送确认
  - LastByteSent：发出去了，还没有收到成功确认的Ack
  - LastByteWritten：上层应用正在写的地方

**2.2.4.3. 滑动窗口示意图**

**2.2.4.3.1 初始时示意图**

![16620671a5cce8f7](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223934.jpg)

- 黑框表示滑动窗口
- \#1表示收到ack确认的数据
- \#2表示还没收到ack的数据
- \#3表示在窗口中还没有发出的（接收方还有空间）
- \#4窗口以外的数据（接收方没空间）

**2.2.4.3.2 滑动过程示意图**

![1662075479974db0](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321223950.jpg)

- 收到36的ack，并发出46-51的字节

**2.2.4.4. 拥塞窗口**

- 解决什么问题：发送方发送速度过快，导致中转路由器拥堵的问题
- 机制：发送方增加一个拥塞窗口（cwnd），每次受到ack，窗口值加1。发送时，取拥塞窗口和接收方发来的窗口大小取最小值发送
- 起到发送方流量控制的作用

**2.2.4.5. 滑动窗口会引发的问题**

**2.2.4.5.1 零窗口**

- 如何发生： 接收端处理速度慢，发送端发送速度快。窗口大小慢慢被调为0
- 如何解决：ZWP技术。发送zwp包给接收方，让接收方ack他的窗口大小。

**2.2.4.5.2 糊涂窗口综合征**

- 如何发生：接收方太忙，取不完数据，导致发送方越来越小。最后只让发送方传几字节的数据。
- 缺点：数据比tcp和ip头小太多，网络利用率太低。
- 如何解决：避免对小的窗口大小做响应。
  - 发送端：前面说到的Nagle算法。
  - 接收端：窗口大小小于某个值，直接ack（0），阻止发送数据。窗口变大后再发。

#### 2.2.5.超时与重传

**2.2.5.1. 概述**

- tcp提供可靠的运输层，使用的方法是确认机制。
- 但是数据和确认都有可能丢失
- tcp通过在发送时设置定时器解决这种问题
- 定时器时间到了还没收到确认，就重传该数据

**2.2.5.2. tcp管理的定时器类型**

- 重传定时器：等待收到确认
- 坚持定时器：使窗口大小信息保持不断流动
- 保活定时器：检测空闲连接崩溃或重启
- 2MSL定时器：检测time_wait状态

**2.2.5.3. 超时重传机制**

**2.2.5.3.1 背景**

- 接收端给发送端的Ack确认只会确认最后一个连续的包
- 比如发送1,2,3,4,5共五份数据，接收端收到1,2，于是回ack3，然后收到4（还没收到3），此时tcp不会跳过3直接确认4，否则发送端以为3也收到了。这时你能想到的方法是什么呢？tcp又是怎么处理的呢？

**2.2.5.3.1 被动等待的超时重传策略**

- 直观的方法是：接收方不做任何处理，等待发送方超时，然后重传。
  - 缺点：发送端不知道该重发3，还是重发3,4,5
- 如果发送方如果只发送3：节省宽度，但是慢
- 如果发送方如果发送3,4,5：快，但是浪费宽带
- 总之，都在被动等待超时，超时可能很长。所以tcp不采用此方法

**2.2.5.3.2 主动的快速重传机制**

**2.2.5.3.2.1 概述**

- 名称为：Fast Retransmit
- 不以实际驱动，而以数据驱动重传

**2.2.5.3.2.2 实现原理**

- 如果包没有送达，就一直ack最后那个可能被丢的包

- 发送方连续收到3相同的ack，就重传。不用等待超时

  ![166202e53b299090](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321224052.jpg)

- 图中发生1,2,3,4,5数据

- 数据1到达，发生ack2

- 数据2因为某些原因没有送到

- 后续收到3的时候，接收端并不是ack4，也不是等待。而是主动ack2

- 收到4,5同理，一直主动ack2

- 客户端收到三次ack2，就重传2

- 2收到后，结合之前收到的3,4,5，直接ack6

**2.2.5.3.2.3 快速重传的利弊**

- 解决了被动等待timeout的问题
- 无法解决重传之前的一个，还是所有的问题。
- 上面的例子中是重传2，还是重传2,3,4,5。因为并不清楚ack2是谁传回来的

**2.2.5.3.3 SACK方法**

**2.2.5.3.3.1 概述**

- 为了解决快速重传的缺点，一种更好的SACK重传策略被提出
- 基于快速重传，同时在tcp头里加了一个SACK的东西
- 解决了什么问题：客户端应该发送哪些超时包的问题

**2.2.5.3.3.2 实现原理**

- SACK记录一个数值范围，表示哪些数据收到了
- linux2.4后默认打开该功能，之前版本需要配置tcp-sack参数
- SACK只是一种辅助的方式，发送方不能完全依赖SACK。主要还是依赖ACK和timout

**2.2.5.3.3.3 Duplicate SACK(D-SACK)**

- 使用SACK标识的范围，还可以知道告知发送方，有哪些数据被重复接收了
- 可以让发送方知道：是发出去的包丢了，还是回来的ack包丢了

**2.2.5.4. 超时时间的确定**

**2.2.5.4.1 背景**

- 路由器和网络流量均会变化
- 所以超时时间肯定不能设置为一个固定值
- 超时长：重发慢，效率低，性能差
- 超时短：并没有丢就重发，导致网络拥塞，导致更多超时和更多重发
- tcp会追踪这些变化，并相应的动态改变超时时间（RTO）

**2.2.5.4.2 如何动态改变**

- 每次重传的时间间隔为上次的一倍，直到最大间隔为64s，称为“指数退避”
- 首次重传到最后放弃重传的时间间隔一般为9min
- 依赖以往的往返时间计算（RTT）动态的计算

**2.2.5.4.3 往返时间（RTT）的计算方法**

- 并不是简单的ack时间和发送时间的差值。因为有重传，网络阻塞等各种变化的因素。
- 而是通过采样多次数值，然后做估算
- tcp使用的方法有：
  - 被平滑的RTT估计器
  - 被平滑的均值偏差估计器

**2.2.5.4.4. 重传时间的具体计算**

- 计算往返时间（RTT），保存测量结果
- 通过测量结果维护一个被平滑的RTT估计器和被平滑的均值偏差估计器
- 根据这两个估计器计算下一次重传时间

**2.2.5.5. 超时重传引发的问题-拥塞**

**2.2.5.5.1 为什么重传会引发拥塞**

- 当网络延迟突然增加时，tcp会重传数据
- 但是过多的重传会导致网络负担加重，从而导致更大的延时和丢包，进入恶性循环
- 也就是tcp的拥塞问题

**2.2.5.5.2 解决拥塞-拥塞控制的算法**

- 慢启动：降低分组进入网络的传输速率
- 拥塞避免：处理丢失分组的算法
- 快速重传
- 快速恢复

#### 2.2.6.其他定时器

**2.2.6.1. 坚持定时器**

**2.2.6.1.1 坚持定时器存在的意义**

- 当窗口大小为0时，接收方会发送一个没有数据，只有窗口大小的ack
- 但是，如果这个ack丢失了会出现什么问题？双方可能因为等待而中止连接
- 坚持定时器周期性的向接收方查询窗口是否被增大。这些发出的报文段称为窗口探查

**2.2.6.1.2 坚持定时器启动时机**

- 发送方被通告接收方窗口大小为0时

**2.2.6.1.3 与超时重传的相同和不同**

- 相同：同样的重传时间间隔
- 不同：窗口探查从不放弃发送，直到窗口被打开或者进程被关闭。而超时重传到一定时间就放弃发送

**2.2.6.2. 保活定时器**

**2.2.6.2.1 保活定时器存在的意义**

- 当tcp上没有数据传输时，服务器如何检测到客户端是否还存活



### 2.3.HTTP协议

#### 2.3.1.引言

HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。目前在WWW中使用的是HTTP/1.0的第六版，HTTP/1.1的规范化工作正在进行之中，而且HTTP-NG(Next Generation of HTTP)的建议已经提出。

HTTP协议的主要特点可概括如下：

1. 支持客户/服务器模式。
2. 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。
3. 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。
4. 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
5. 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。

#### 2.3.2.URL

http（超文本传输协议）是一个基于请求与响应模式的、无状态的、应用层的协议，常基于TCP的连接方式，HTTP1.1版本中给出一种持续连接的机制，绝大多数的Web开发，都是构建在HTTP协议之上的Web应用。

HTTP URL (URL是一种特殊类型的URI，包含了用于查找某个资源的足够的信息)的格式如下：

`http://host[":"port][abs_path]`

http表示要通过HTTP协议来定位网络资源；host表示合法的Internet主机域名或者IP地址；port指定一个端口号，为空则使用缺省端口80；abs_path指定请求资源的URI；如果URL中没有给出abs_path，那么当它作为请求URI时，必须以“/”的形式给出，通常这个工作浏览器自动帮我们完成。

eg:

1、输入：[www.guet.edu.cn](http://www.guet.edu.cn/)
浏览器自动转换成：http://www.guet.edu.cn/

2、http:192.168.0.116:8080/index.jsp 

#### 2.3.3.HTTP 请求

http请求由三部分组成，分别是：请求行、消息报头、请求正文

1、请求行以一个方法符号开头，以空格分开，后面跟着请求的URI和协议的版本，格式如下：`Method Request-URI HTTP-Version CRLF `

其中 Method表示请求方法；Request-URI是一个统一资源标识符；HTTP-Version表示请求的HTTP协议版本；CRLF表示回车和换行（除了作为结尾的CRLF外，不允许出现单独的CR或LF字符）。

请求方法（所有方法全为大写）有多种，各个方法的解释如下：

- GET   请求获取Request-URI所标识的资源

- POST  在Request-URI所标识的资源后附加新的数据

- HEAD  请求获取由Request-URI所标识的资源的响应消息报头

- PUT   请求服务器存储一个资源，并用Request-URI作为其标识

- DELETE 请求服务器删除Request-URI所标识的资源

- TRACE  请求服务器回送收到的请求信息，主要用于测试或诊断

- CONNECT 保留将来使用

- OPTIONS 请求查询服务器的性能，或者查询与资源相关的选项和需求

**应用举例：**

GET方法：在浏览器的地址栏中输入网址的方式访问网页时，浏览器采用GET方法向服务器获取资源，eg:GET /form.html HTTP/1.1 (CRLF)

POST方法要求被请求服务器接受附在请求后面的数据，常用于提交表单。
eg：POST /reg.jsp HTTP/ (CRLF)

```
Accept:image/gif,image/x-xbit,... (CRLF)
...
HOST:www.guet.edu.cn (CRLF)
Content-Length:22 (CRLF)
Connection:Keep-Alive (CRLF)
Cache-Control:no-cache (CRLF)
(CRLF)     //该CRLF表示消息报头已经结束，在此之前为消息报头
user=jeffrey&pwd=1234 //此行以下为提交的数据
```

HEAD方法与GET方法几乎是一样的，对于HEAD请求的回应部分来说，它的HTTP头部中包含的信息与通过GET请求所得到的信息是相同的。利用这个方法，不必传输整个资源内容，就可以得到Request-URI所标识的资源的信息。该方法常用于测试超链接的有效性，是否可以访问，以及最近是否更新。

2、请求报头后述

3、请求正文(略) 

#### 2.3.4.HTTP响应

在接收和解释请求消息后，服务器返回一个HTTP响应消息。

HTTP响应也是由三个部分组成，分别是：状态行、消息报头、响应正文

1、状态行格式如下：

HTTP-Version Status-Code Reason-Phrase CRLF

其中，HTTP-Version表示服务器HTTP协议的版本；Status-Code表示服务器发回的响应状态代码；Reason-Phrase表示状态代码的文本描述。

状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值：

- 1xx：指示信息--表示请求已接收，继续处理
- 2xx：成功--表示请求已被成功接收、理解、接受
- 3xx：重定向--要完成请求必须进行更进一步的操作
- 4xx：客户端错误--请求有语法错误或请求无法实现
- 5xx：服务器端错误--服务器未能实现合法的请求

常见状态代码、状态描述、说明：

- 200 OK   //客户端请求成功
- 400 Bad Request //客户端请求有语法错误，不能被服务器所理解
- 401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 
- 403 Forbidden //服务器收到请求，但是拒绝提供服务
- 404 Not Found //请求资源不存在，eg：输入了错误的URL
- 500 Internal Server Error //服务器发生不可预期的错误
- 503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常

eg：HTTP/1.1 200 OK （CRLF）

2、响应报头后述

3、响应正文就是服务器返回的资源的内容 

#### 2.3.4.消息报头

HTTP消息由客户端到服务器的请求和服务器到客户端的响应组成。请求消息和响应消息都是由开始行（对于请求消息，开始行就是请求行，对于响应消息，开始行就是状态行），消息报头（可选），空行（只有CRLF的行），消息正文（可选）组成。

HTTP消息报头包括普通报头、请求报头、响应报头、实体报头。

每一个报头域都是由名字+“：”+空格+值 组成，消息报头域的名字是大小写无关的。

1、普通报头
在普通报头中，有少数报头域用于所有的请求和响应消息，但并不用于被传输的实体，只用于传输的消息。

eg：

Cache-Control  用于指定缓存指令，缓存指令是单向的（响应中出现的缓存指令在请求中未必会出现），且是独立的（一个消息的缓存指令不会影响另一个消息处理的缓存机制），HTTP1.0使用的类似的报头域为Pragma。

请求时的缓存指令包括：no-cache（用于指示请求或响应消息不能缓存）、no-store、max-age、max-stale、min-fresh、only-if-cached;

响应时的缓存指令包括：public、private、no-cache、no-store、no-transform、must-revalidate、proxy-revalidate、max-age、s-maxage.

eg：为了指示IE浏览器（客户端）不要缓存页面，服务器端的JSP程序可以编写如下：response.sehHeader("Cache-Control","no-cache");

//response.setHeader("Pragma","no-cache");作用相当于上述代码，通常两者//合用

这句代码将在发送的响应消息中设置普通报头域：Cache-Control:no-cache

Date普通报头域表示消息产生的日期和时间

Connection普通报头域允许发送指定连接的选项。例如指定连接是连续，或者指定“close”选项，通知服务器，在响应完成后，关闭连接

2、请求报头

请求报头允许客户端向服务器端传递请求的附加信息以及客户端自身的信息。

常用的请求报头

- Accept

  Accept请求报头域用于指定客户端接受哪些类型的信息。eg：Accept：image/gif，表明客户端希望接受GIF图象格式的资源；Accept：text/html，表明客户端希望接受html文本。

- Accept-Charset
  Accept-Charset请求报头域用于指定客户端接受的字符集。eg：Accept-Charset:iso-8859-1,gb2312.如果在请求消息中没有设置这个域，缺省是任何字符集都可以接受。

- Accept-Encoding
  Accept-Encoding请求报头域类似于Accept，但是它是用于指定可接受的内容编码。eg：Accept-Encoding:gzip.deflate.如果请求消息中没有设置这个域服务器假定客户端对各种内容编码都可以接受。

- Accept-Language
  Accept-Language请求报头域类似于Accept，但是它是用于指定一种自然语言。eg：Accept-Language:zh-cn.如果请求消息中没有设置这个报头域，服务器假定客户端对各种语言都可以接受。

- Authorization
  Authorization请求报头域主要用于证明客户端有权查看某个资源。当浏览器访问一个页面时，如果收到服务器的响应代码为401（未授权），可以发送一个包含Authorization请求报头域的请求，要求服务器对其进行验证。

- Host（发送请求时，该报头域是必需的）
  Host请求报头域主要用于指定被请求资源的Internet主机和端口号，它通常从HTTP URL中提取出来的，eg：
  我们在浏览器中输入：http://www.guet.edu.cn/index.html

  浏览器发送的请求消息中，就会包含Host请求报头域，如下：

  Host：[www.guet.edu.cn](http://www.guet.edu.cn/)
  此处使用缺省端口号80，若指定了端口号，则变成：Host：[www.guet.edu.cn](http://www.guet.edu.cn/):指定端口号

- User-Agent
  我们上网登陆论坛的时候，往往会看到一些欢迎信息，其中列出了你的操作系统的名称和版本，你所使用的浏览器的名称和版本，这往往让很多人感到很神奇，实际上，服务器应用程序就是从User-Agent这个请求报头域中获取到这些信息。User-Agent请求报头域允许客户端将它的操作系统、浏览器和其它属性告诉服务器。不过，这个报头域不是必需的，如果我们自己编写一个浏览器，不使用User-Agent请求报头域，那么服务器端就无法得知我们的信息了。
  请求报头举例：

  ```
  GET /form.html HTTP/1.1 (CRLF)
  Accept:image/gif,image/x-xbitmap,image/jpeg,application/x-shockwave-flash,application/vnd.ms-excel,application/vnd.ms-powerpoint,application/msword,*/* (CRLF)
  Accept-Language:zh-cn (CRLF)
  Accept-Encoding:gzip,deflate (CRLF)
  If-Modified-Since:Wed,05 Jan 2007 11:21:25 GMT (CRLF)
  If-None-Match:W/"80b1a4c018f3c41:8317" (CRLF)
  User-Agent:Mozilla/4.0(compatible;MSIE6.0;Windows NT 5.0) (CRLF)
  Host:www.guet.edu.cn (CRLF)
  Connection:Keep-Alive (CRLF)
  (CRLF)
  ```

3、响应报头
响应报头允许服务器传递不能放在状态行中的附加响应信息，以及关于服务器的信息和对Request-URI所标识的资源进行下一步访问的信息。
常用的响应报头

- Location
  Location响应报头域用于重定向接受者到一个新的位置。Location响应报头域常用在更换域名的时候。
- Server
  Server响应报头域包含了服务器用来处理请求的软件信息。与User-Agent请求报头域是相对应的。下面是
  Server响应报头域的一个例子：
  Server：Apache-Coyote/1.1
- WWW-Authenticate
  WWW-Authenticate响应报头域必须被包含在401（未授权的）响应消息中，客户端收到401响应消息时候，并发送Authorization报头域请求服务器对其进行验证时，服务端响应报头就包含该报头域。

eg：WWW-Authenticate:Basic realm="Basic Auth Test!" //可以看出服务器对请求资源采用的是基本验证机制。

4、实体报头

请求和响应消息都可以传送一个实体。一个实体由实体报头域和实体正文组成，但并不是说实体报头域和实体正文要在一起发送，可以只发送实体报头域。实体报头定义了关于实体正文（eg：有无实体正文）和请求所标识的资源的元信息。

常用的实体报头

- Content-Encoding
  Content-Encoding实体报头域被用作媒体类型的修饰符，它的值指示了已经被应用到实体正文的附加内容的编码，因而要获得Content-Type报头域中所引用的媒体类型，必须采用相应的解码机制。Content-Encoding这样用于记录文档的压缩方法，eg：Content-Encoding：gzip
- Content-Language
  Content-Language实体报头域描述了资源所用的自然语言。没有设置该域则认为实体内容将提供给所有的语言阅读
  者。eg：Content-Language:da
- Content-Length
  Content-Length实体报头域用于指明实体正文的长度，以字节方式存储的十进制数字来表示。
- Content-Type
  Content-Type实体报头域用语指明发送给接收者的实体正文的媒体类型。eg：
  Content-Type:text/html;charset=ISO-8859-1
  Content-Type:text/html;charset=GB2312
- Last-Modified
  Last-Modified实体报头域用于指示资源的最后修改日期和时间。
- Expires
  Expires实体报头域给出响应过期的日期和时间。为了让代理服务器或浏览器在一段时间以后更新缓存中(再次访问曾访问过的页面时，直接从缓存中加载，缩短响应时间和降低服务器负载)的页面，我们可以使用Expires实体报头域指定页面过期的时间。eg：Expires：Thu，15 Sep 2006 16:23:12 GMT
  HTTP1.1的客户端和缓存必须将其他非法的日期格式（包括0）看作已经过期。eg：为了让浏览器不要缓存页面，我们也可以利用Expires实体报头域，设置为0，jsp中程序如下：response.setDateHeader("Expires","0");

 

#### 2.3.5.利用telnet观察http协议的通讯过程

**实验目的及原理：**

利用MS的telnet工具，通过手动输入http请求信息的方式，向服务器发出请求，服务器接收、解释和接受请求后，会返回一个响应，该响应会在telnet窗口上显示出来，从而从感性上加深对http协议的通讯过程的认识。

 **实验步骤：**

**1、打开telnet**

1.1 打开telnet

`运行-->cmd-->telnet`

1.2 打开telnet回显功能

`set localecho`

**2、连接服务器并发送请求**

2.1 open [www.guet.edu.cn](http://www.guet.edu.cn/) 80 //注意端口号不能省略

```
HEAD /index.asp HTTP/1.0

Host:www.guet.edu.cn
```

  我们可以变换请求方法,请求桂林电子主页内容,输入消息如下

```
open [www.guet.edu.cn](http://www.guet.edu.cn/) 80 

GET /index.asp HTTP/1.0 //请求资源的内容
Host:www.guet.edu.cn 
```

2.2 open [www.sina.com.cn](http://www.sina.com.cn/) 80 //在命令提示符号下直接输入telnet [www.sina.com.cn](http://www.sina.com.cn/) 80

```
HEAD /index.asp HTTP/1.0
Host:www.sina.com.cn
```




**3 实验结果：**

3.1 请求信息2.1得到的响应是:

```
HTTP/1.1 200 OK                       //请求成功
Server: Microsoft-IIS/5.0                  //web服务器
Date: Thu,08 Mar 200707:17:51 GMT
Connection: Keep-Alive                 
Content-Length: 23330
Content-Type: text/html
Expries: Thu,08 Mar 2007 07:16:51 GMT
Set-Cookie: ASPSESSIONIDQAQBQQQB=BEJCDGKADEDJKLKKAJEOIMMH; path=/
Cache-control: private

//资源内容省略
```

3.2 请求信息2.2得到的响应是:

```
HTTP/1.0 404 Not Found    //请求失败
Date: Thu, 08 Mar 2007 07:50:50 GMT
Server: Apache/2.0.54 <Unix>
Last-Modified: Thu, 30 Nov 2006 11:35:41 GMT
ETag: "6277a-415-e7c76980"
Accept-Ranges: bytes
X-Powered-By: mod_xlayout_jh/0.0.1vhs.markII.remix
Vary: Accept-Encoding
Content-Type: text/html
X-Cache: MISS from zjm152-78.sina.com.cn
Via: 1.0 zjm152-78.sina.com.cn:80<squid/2.6.STABLES-20061207>
X-Cache: MISS from th-143.sina.com.cn
Connection: close
失去了跟主机的连接

按任意键继续...
```

**4 .注意事项：**

- 出现输入错误，则请求不会成功。
- 报头域不分大小写。
- 更深一步了解HTTP协议，可以查看RFC2616，在http://www.letf.org/rfc上找到该文件。
- 开发后台程序必须掌握http协议

#### 2.3.6.HTTP协议相关技术补充

**1、基础：**

高层协议有：文件传输协议FTP、电子邮件传输协议SMTP、域名系统服务DNS、网络新闻传输协议NNTP和HTTP协议等

中介由三种：代理(Proxy)、网关(Gateway)和通道(Tunnel)，一个代理根据URI的绝对格式来接受请求，重写全部或部分消息，通过 URI的标识把已格式化过的请求发送到服务器。网关是一个接收代理，作为一些其它服务器的上层，并且如果必须的话，可以把请求翻译给下层的服务器协议。一 个通道作为不改变消息的两个连接之间的中继点。当通讯需要通过一个中介(例如：防火墙等)或者是中介不能识别消息的内容时，通道经常被使用。

- 代理(Proxy)：一个中间程序，它可以充当一个服务器，也可以充当一个客户机，为其它客户机建立请求。请求是通过可能的翻译在内部或经过传递到其它的 服务器中。一个代理在发送请求信息之前，必须解释并且如果可能重写它。代理经常作为通过防火墙的客户机端的门户，代理还可以作为一个帮助应用来通过协议处 理没有被用户代理完成的请求。

- 网关(Gateway)：一个作为其它服务器中间媒介的服务器。与代理不同的是，网关接受请求就好象对被请求的资源来说它就是源服务器；发出请求的客户机并没有意识到它在同网关打交道。

  网关经常作为通过防火墙的服务器端的门户，网关还可以作为一个协议翻译器以便存取那些存储在非HTTP系统中的资源。

- 通道(Tunnel)：是作为两个连接中继的中介程序。一旦激活，通道便被认为不属于HTTP通讯，尽管通道可能是被一个HTTP请求初始化的。当被中继 的连接两端关闭时，通道便消失。当一个门户(Portal)必须存在或中介(Intermediary)不能解释中继的通讯时通道被经常使用。

**2、协议分析的优势—HTTP分析器检测网络攻击**

以模块化的方式对高层协议进行分析处理，将是未来入侵检测的方向。

HTTP及其代理的常用端口80、3128和8080在network部分用port标签进行了规定

**3、HTTP协议Content Lenth限制漏洞导致拒绝服务攻击**

使用POST方法时，可以设置ContentLenth来定义需要传送的数据长度，例如ContentLenth:999999999，在传送完成前，内 存不会释放，攻击者可以利用这个缺陷，连续向WEB服务器发送垃圾数据直至WEB服务器内存耗尽。这种攻击方法基本不会留下痕迹。

**4、利用HTTP协议的特性进行拒绝服务攻击的一些构思**

服务器端忙于处理攻击者伪造的TCP连接请求而无暇理睬客户的正常请求（毕竟客户端的正常请求比率非常之小），此时从正常客户的角度看来，服务器失去响应，这种情况我们称作：服务器端受到了SYNFlood攻击（SYN洪水攻击）。

而Smurf、TearDrop等是利用ICMP报文来Flood和IP碎片攻击的。本文用“正常连接”的方法来产生拒绝服务攻击。

19端口在早期已经有人用来做Chargen攻击了，即Chargen_Denial_of_Service，但是！他们用的方法是在两台Chargen 服务器之间产生UDP连接，让服务器处理过多信息而DOWN掉，那么，干掉一台WEB服务器的条件就必须有2个：1.有Chargen服务2.有HTTP 服务
方法：攻击者伪造源IP给N台Chargen发送连接请求（Connect），Chargen接收到连接后就会返回每秒72字节的字符流（实际上根据网络实际情况，这个速度更快）给服务器。

**5、Http指纹识别技术**

Http指纹识别的原理大致上也是相同的：记录不同服务器对Http协议执行中的微小差别进行识别.Http指纹识别比TCP/IP堆栈指纹识别复杂许 多,理由是定制Http服务器的配置文件、增加插件或组件使得更改Http的响应信息变的很容易,这样使得识别变的困难；然而定制TCP/IP堆栈的行为 需要对核心层进行修改,所以就容易识别.

要让服务器返回不同的Banner信息的设置是很简单的,象Apache这样的开放源代码的Http服务器,用户可以在源代码里修改Banner信息,然 后重起Http服务就生效了；对于没有公开源代码的Http服务器比如微软的IIS或者是Netscape,可以在存放Banner信息的Dll文件中修 改,相关的文章有讨论的,这里不再赘述,当然这样的修改的效果还是不错的.另外一种模糊Banner信息的方法是使用插件。
常用测试请求：

1：HEAD/Http/1.0发送基本的Http请求

2：DELETE/Http/1.0发送那些不被允许的请求,比如Delete请求

3：GET/Http/3.0发送一个非法版本的Http协议请求

4：GET/JUNK/1.0发送一个不正确规格的Http协议请求

Http指纹识别工具Httprint,它通过运用统计学原理,组合模糊的逻辑学技术,能很有效的确定Http服务器的类型.它可以被用来收集和分析不同Http服务器产生的签名。

**6、其他**

为了提高用户使用浏览器时的性能，现代浏览器还支持并发的访问方式，浏览一个网页时同时建立多个连接，以迅速获得一个网页上的多个图标，这样能更快速完成整个网页的传输。

HTTP1.1中提供了这种持续连接的方式，而下一代HTTP协议：HTTP-NG更增加了有关会话控制、丰富的内容协商等方式的支持，来提供
更高效率的连接。



### 2.4.HTTPS协议

#### 2.4.1.为什么需要深入理解HTTPS协议

因为目前越来越多的网站或者app已经全面接入HTTPS，APPLE官方也建议APP全面使用HTTPS，何况国内这种节操都没有喜欢劫持网络请求的运营商在，没有HTTPS 实在是毁用户体验。**多数人都是只知道HTTPS是基于HTTP的，有加密功能，但不知道这个是怎么实现的，相信我，作为一个开发者你以后始终会碰到HTTPS的相关问题，从源头弄懂这份协议很有必要。**

#### 2.4.2.对称加密和非对称加密

这也是理解https的重要基础之一。这里涉及到很多复杂的算法，我并不精通算法和密码学，所以这里不讲的太细。你们只要知道个大概即可：

对称加密：加密和解密都用一个密钥，有点是速度快。缺点吗，显而易见的是 双方要用这个通信的话 必须得把密钥告知对方， 但是这个密钥一旦被截获了，就可以随便decode出来明文。实际上不够安全。

非对称加密：有**一对**密钥，即有公钥也有私钥。公钥随便发，私钥不会发出去 各自保管。用一个加密的话，解密就只能用另外一个。比如你向银行请求一个公钥，银行把公钥发给你，你用公钥加密一条信息以后 再发给银行，然后银行用私钥解密信息。这个过程就算有人拿到公钥，**但是因为非对称加密用一个加密 只能用另外一个解密**，所以 拿到这公钥也没用，因为无法使用公钥解密，能解密的私钥还在银行那里，银行当然不会传出去，所以非对称加密很安全。 但是这种非对称加密非常消耗资源，速度极慢，所以要有限使用。不能无节制使用。

HASH加密算法：这个就好像MD5这样的加密方式，是不可逆的。

#### 2.4.3.确保安全通信的三个原则

**A.数据内容的加密**

这个很好理解是吧，敏感信息肯定要加密的，明文传输等于自杀。不过多解释了。

**B.通讯双方的身份校验**

这个很多人不理解，这是啥意思，按道理说我们用非对称加密应该就完美了啊。但是谨记我们的数据包不是从A直接到B的。 中间要经过无数次的路由器转发等等，这个中间一旦有人截获了我们的数据包，换成自己的数据包，就很危险了。 所以我们还需要一种机制能校验通讯双方的身份。**确保我是在和我老婆说话 而不是在我和丈母娘说话。**

**C.数据内容的完整性**

这个也不是很容易理解，按道理说TCP是能保证数据有序完整的到达对方的。但是不要忘记中间我们经过的无数次路由器转发， 可能被劫持，被劫持以后可能会对数据包进行篡改，这个时候我们需要一种机制保护我们的数据不被篡改，即使被篡改 也能被我们察觉，**确保我对我老婆写的信能完整的让我老婆看到，而不是只看到一半。**

#### 2.4.4.https的设计思路

根据前面我们阐述的加密算法和安全通信三原则，为了保证我们的通信能够安全进行，可以试想出一种流程来保证通信安全：

- 服务器为每个客户端生成一个公钥，将公钥发送给客户端
- 客户端选择一个加密算法，然后用公钥加密以后发送给服务器
- 服务器收到这个公钥加密后的算法以后拿自己的私钥解密，然后就知道这个加密算法是哪个了。今后就一直用这个算法通信。

目前来看，这个思路是不是很完美。公钥即使被中间人截获以后也没用，因为拿到公钥也解密不出来到底双方是用哪种算法加密的。 但有个重大缺陷：

**中间人可以将服务器发送的公钥包进行掉包，客户端怎么知道这个公钥是真的服务器发送的还是假的中间人给的非法公钥呢？**

可以看这张图，基本上中间人攻击就是这个图所示的意思。

![1604db933ee71970](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231336.jpg)

#### 2.4.5.解决中间人攻击问题

这个问题的解决办法其实也很粗暴：

- 使用权威的第三方机构也就是CA向安全的服务器颁发证书。来证明这台服务器的合法性。
- 服务器通过这个证书来把自己的公钥加密以后发给客户端
- 客户端收到这个加密后的公钥以后 ，就用第三方机构的公钥 把这个服务器返回的加密后的公钥 解密 从而得到真正的服务器 的公钥

带来的问题：

客户端到哪去取第三方公钥?

- 你的操作系统或者浏览器自身就带有权威机构的第三方公钥
- 如果中间人得到CA认证怎么办？这种情况基本没办法处理，如果发生，那么这个CA下面所有的证书都被认为非法了。所以 CA审核也很严格啊

#### 2.4.6.CA证书是收费的啊，我不想交钱咋办呢

可以自己制作证书，然后把这个证书的公钥放在客户端（例如app的安装目录下），这样app只要使用自己的证书公钥即可 解密了，不需要使用系统的。但是这样带来的问题是，如果有人获取到了你这个公钥证书咋办？ 数字签名认证算法即可保证此类问题，其实简单来说就是服务器和客户端事先约定好一种加密规则即可，就可以得知是否被篡改。 这部分由于不是重点，暂时不讲的太细，只要知道有这么个事即可。实际上你弄懂整个https以后这个地方就自然而然也能 想明白了。

#### 2.4.7.有了上述基础，我们终于可以按照科班的方式来理解HTTPS真正的流程

为什么HTTPS的流程要放在最后再讲，因为放在前面讲，根本不会理解为啥要这么做，很快就会忘记。有了前面的基础 再来看这个流程，就会恍然大悟。

![1604dd9dd58b3ec9](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231345.jpg)

- 先看蓝色的部分，可以看出来，这是tcp链接。所以https的加密层也是在tcp之上的。
- 客户端首先发起clientHello消息。包含一个客户端随机生成的random1 数字，客户端支持的加密算法，以及SSL信息。
- 服务器收到客户端的clientHello消息以后，取出客户端法发来的random1数字，并且取出客户端发来的支持的加密算法， 然后选出一个加密算法，并生成一个随机数random2，发送给客户端serverhello
- 让客户端对服务器进行身份校验,服务端通过将自己的公钥通过数字证书的方式发送给客户端
- 客户端收到服务端传来的证书后，先从 CA 验证该证书的合法性，验证通过后取出证书中的服务端公钥，再生成一个随机数 Random3，再用服务端公钥非对称加密 Random3 生成 PreMaster Key。并将PreMaster Key发送到服务端,服务端通过私钥将PreMaster Key解密获取到Random3,此时客户端和服务器都持有三个随机数Random1 Random2 Random3,双方在通过这三个随即书生成一个对称加密的密钥.双方根据这三个随即数经过相同的算法生成一个密钥,而以后应用层传输的数据都使用这套密钥进行加密.
- Change Cipher Spec:告诉客户端以后的通讯都使用这一套密钥来进行.

**最后ApplicationData 全部使用对称加密的原因就是非对称加密太卡，对称加密不影响性能。所以实际上也看的出来 HTTPS的真正目的就是保证对称加密的 密钥不被破解，不被替换，不被中间人攻击，如果发生了上述情况，那么HTTPS的加密 层也能获知，避免发生事故。**

#### 2.4.8.最后我们用WireShark再来还原一次HTTPS的交互过程把

目标访问地址就用github吧。 抓出来是这样的。

![1604df9e17cdbe39](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231359.jpg)

注意看tlsv1的就可以了这个就是加密层。

下面就来逐步分析

- ClientHello

  ![1604e0513b2b5493](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231410.jpg)

- severHello

  ![1604e09df104d8b7](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231424.jpg)

注意到这里服务器和客户端就有2个随机数了。并且加密算法也确定了。

- severHelloDone

  ![1604e100a534c5c7](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231433.jpg)

这部分主要是发送证书信息的 点开以后 证书的详细信息都能看到 另外serverhellodone的意思就是服务器的工作都完毕了。

![1604e7e3af743fd6](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231446.jpg)

- 来看看第四步，客户端-->服务端 到底做了什么

![1604e81eab12f5bc](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231456.jpg)

可以看出来这里一共有三个步骤，我们来依次分析 这三次动作都做了什么

**Client Key Exchange**

![1604e854b0d3bc45](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231507.jpg)

服务器收到这个random3的加密信息以后，用自己的私钥解密，这样服务器和客户端就共同拥有了random 123 3组随机数，然后用这三组数据生成一个密钥，这个密钥就是后面我们applicationdata交互时使用的对称加密的密钥了

- 第五步 服务端-客户端

  ![1604e96ff2555df1](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231517.jpg)

- 最后看看第六步也是最后一步，传输数据层。

  ![1604e9b06c747ef4](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231526.jpg)

#### 2.4.9.new session ticket是啥意思

![1604ea166466c73a](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231538.jpg)

这个session ticket就是服务器最后一步的时候传给客户端的一个数据。 这个加密数据客户端收到以后就可以保存下来，这样下一次再请求https的 时候，就可以把这个session ticket发过去，这样可以省很多握手的时间和 资源消耗。（前面我们分析的4-5步其实已经相当复杂了，尤其是非对称加密对服务端的资源消耗相当之大）

**实际上对于多数浏览器来说，指向同一个域名的https连接，我们都会有意识的让第一个https连接完成握手之后再连接第n个 https。因为这样 后续的https 就可以携带相关信息，可以省很多资源**

这个ticket实际上就有点类似cookie。

在笔者的这次访问chrome-gitub的过程中，浏览器并没有使用ticket技术 而是使用的seession id技术：

![1604eb4df7d60701](https://homan-blog.oss-cn-beijing.aliyuncs.com/study-demo/java-core-demo/20210321231551.jpg)

sessionid 实际上作用和ticket差不多，但是sessionid 无法做到服务器之间同步，毕竟id 存在服务器内存中，负载均衡带来的状态机同步是一个大问题。

#### 2.4.10.总结

其实HTTPS总结起来就是3次tcp握手-5次TLS握手。搞清楚每一步做什么， 用的是对称加密还是非对称加密，整个流程就肯定能搞清楚了。 以后遇到类似的问题就能快速定位优化了。甚至抓取BAT的HTTPS接口 数据都不是难事。如果有需要的话大家就在下方留言，我会尽快 教大家如何抓取bat的https接口数据 并且decode出明文。



### 2.5.UDP协议

**1.UDP简要介绍**

UDP是传输层协议，和TCP协议处于一个分层中，但是与TCP协议不同，UDP协议并不提供超时重传，出错重传等功能，也就是说其是不可靠的协议。

**2.5.2.UDP协议头**

**2.5.2.1.UDP端口号**

由于很多软件需要用到UDP协议，所以UDP协议必须通过某个标志用以区分不同的程序所需要的数据包。端口号的功能就在于此，例如某一个UDP程序A在系统中注册了3000端口，那么，以后从外面传进来的目的端口号为3000的UDP包都会交给该程序。端口号理论上可以有2^16这么多。因为它的长度是16个bit

**2.5.2.2.UDP检验和**

这是一个可选的选项，并不是所有的系统都对UDP数据包加以检验和数据(相对TCP协议的必须来说)，但是RFC中标准要求，发送端应该计算检验和。

UDP检验和覆盖UDP协议头和数据，这和IP的检验和是不同的，IP协议的检验和只是覆盖IP数据头，并不覆盖所有的数据。UDP和TCP都包含一个伪首部，这是为了计算检验和而摄制的。伪首部甚至还包含IP地址这样的IP协议里面都有的信息，目的是让UDP两次检查数据是否已经正确到达目的地。如果发送端没有打开检验和选项，而接收端计算检验和有差错，那么UDP数据将会被悄悄的丢掉（不保证送达），而不产生任何差错报文。

**2.5.2.3.UDP长度**

UDP可以很长很长，可以有65535字节那么长。但是一般网络在传送的时候，一次一般传送不了那么长的协议（涉及到MTU的问题），就只好对数据分片，当然，这些是对UDP等上级协议透明的，UDP不需要关心IP协议层对数据如何分片，下一个章节将会稍微讨论一些分片的策略。

**2.5.3.IP分片**

IP在从上层接到数据以后，要根据IP地址来判断从那个接口发送数据（通过选路），并进行MTU的查询，如果数据大小超过MTU就进行数据分片。数据的分片是对上层和下层透明，而数据也只是到达目的地还会被重新组装，不过不用担心，IP层提供了足够的信息进行数据的再组装。

在IP头里面，16bit识别号唯一记录了一个IP包的ID,具有同一个ID的IP片将会被重新组装；而13位片偏移则记录了某IP片相对整个包的位置；而这两个表示中间的3bit标志则标示着该分片后面是否还有新的分片。这三个标示就组成了IP分片的所有信息，接受方就可以利用这些信息对IP数据进行重新组织（就算是后面的分片比前面的分片先到，这些信息也是足够了）。

因为分片技术在网络上被经常的使用，所以伪造IP分片包进行流氓攻击的软件和人也就层出不穷。

可以用Trancdroute程序来进行简单的MTU侦测。请参看教材。

**2.5.4.UDP和ARP之间的交互式用**

这是不常被人注意到的一个细节，这是针对一些系统地实现来说的。当ARP缓存还是空的时候。UDP在被发送之前一定要发送一个ARP请求来获得目的主机的MAC地址，如果这个UDP的数据包足够大，大到IP层一定要对其进行分片的时候，想象中，该UDP数据包的第一个分片会发出一个ARP查询请求，所有的分片都辉等到这个查询完成以后再发送。事实上是这样吗？

结果是，某些系统会让每一个分片都发送一个ARP查询，所有的分片都在等待，但是接受到第一个回应的时候，主机却只发送了最后一个数据片而抛弃了其他，这实在是让人匪夷所思。这样，因为分片的数据不能被及时组装，接受主机将会在一段时间内将永远无法组装的IP数据包抛弃，并且发送组装超时的ICMP报文（其实很多系统不产生这个差错），以保证接受主机自己的接收端缓存不被那些永远得不到组装的分片充满。

**2.5.5.ICMP源站抑制差错**

当目标主机的处理速度赶不上数据接收的速度，因为接受主机的IP层缓存会被占满，所以主机就会发出一个“我受不了”的一个ICMP报文。

**2.5.6.UDP服务器设计**

UDP协议的某些特性将会影响我们的服务器程序设计，大致总结如下：

关于客户IP和地址：服务器必须有根据客户IP地址和端口号判断数据包是否合法的能力（这似乎要求每一个服务器都要具备）

关于目的地址：服务器必须要有过滤广播地址的能力。

关于数据输入：通常服务器系统的每一个端口号都会和一块输入缓冲区对应，进来的输入根据先来后到的原则等待服务器的处理，所以难免会出现缓冲区溢出的问题，这种情况下，UDP数据包可能会被丢弃，而应用服务器程序本身并不知道这个问题。

服务器应该限制本地IP地址，就是说它应该可以把自己绑定到某一个网络接口的某一个端口上。





